{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0fedc8-0057-4cb6-b757-8aa164f6ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983df560-2a48-49f9-a28e-da652d2940ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_odds = {\n",
    "    \"Stetson\": {\"opponent\": \"UConn\", \"Over/Under\": 145.5, \"Spread\": -27.5, \"Home\": False},\n",
    "    \"FAU\": {\"opponent\": \"Northwestern\", \"Over/Under\": 142.5, \"Spread\": -4.5, \"Home\": True},\n",
    "    \"UAB\": {\"opponent\": \"San_Diego_State\", \"Over/Under\": 140.0, \"Spread\": -6.5, \"Home\": False},\n",
    "    \"Auburn\": {\"opponent\": \"Yale\", \"Over/Under\": 140.5, \"Spread\": -14.0, \"Home\": True},\n",
    "    \"BYU\": {\"opponent\": \"Duquesne\", \"Over/Under\": 142.0, \"Spread\": -9.5, \"Home\": False},\n",
    "    \"Morehead_St\": {\"opponent\": \"Illinois\", \"Over/Under\": 147.0, \"Spread\": -11.0, \"Home\": False},\n",
    "    \"Drake\": {\"opponent\": \"Washington_St\", \"Over/Under\": 138.5, \"Spread\": +1.0, \"Home\": False},\n",
    "    \"South_Dakota_St\": {\"opponent\": \"Iowa_State\", \"Over/Under\": 135.0, \"Spread\": -15.0, \"Home\": False},\n",
    "    \"Longwood\": {\"opponent\": \"Houston\", \"Over/Under\": 129.5, \"Spread\": -24.0, \"Home\": False},\n",
    "    \"Nebraska\": {\"opponent\": \"Texas_A&M\", \"Over/Under\": 149.0, \"Spread\": +1.0, \"Home\": True},\n",
    "    \"Wisconsin\": {\"opponent\": \"JMU\", \"Over/Under\": 144.0, \"Spread\": -5.0, \"Home\": True},\n",
    "    \"Vermont\": {\"opponent\": \"Duke\", \"Over/Under\": 133.0, \"Spread\": -12.5, \"Home\": False},\n",
    "    \"Texas_Tech\": {\"opponent\": \"NC_State\", \"Over/Under\": 147.0, \"Spread\": -5.0, \"Home\": True},\n",
    "    \"Kentucky\": {\"opponent\": \"Oakland\", \"Over/Under\": 160.0, \"Spread\": -13.5, \"Home\": True},\n",
    "    \"Florida\": {\"opponent\": \"Colorado\", \"Over/Under\": 157.0, \"Spread\": +1.0, \"Home\": True},\n",
    "    \"Western_Kentucky\": {\"opponent\": \"Marquette\", \"Over/Under\": 157.0, \"Spread\": -14.5, \"Home\": False},\n",
    "    \"Northwestern\": {\"opponent\": \"UConn\", \"Over/Under\": 136.0, \"Spread\": -13.5, \"Home\": False},\n",
    "    \"Yale\": {\"opponent\": \"San_Diego_State\", \"Over/Under\": 131.5, \"Spread\": -5.5, \"Home\": False},\n",
    "    \"Duquesne\": {\"opponent\": \"Illinois\", \"Over/Under\": 147.0, \"Spread\": -10.0, \"Home\": False},\n",
    "    \"Washington_St\": {\"opponent\": \"Iowa_State\", \"Over/Under\": 127.0, \"Spread\": -6.5, \"Home\": False},\n",
    "    \"Texas_A&M\": {\"opponent\": \"Houston\", \"Over/Under\": 135.5, \"Spread\": -8.5, \"Home\": False},\n",
    "    \"JMU\": {\"opponent\": \"Duke\", \"Over/Under\": 147.5, \"Spread\": -6.0, \"Home\": False},\n",
    "    \"Oakland\": {\"opponent\": \"NC_State\", \"Over/Under\": 147.0, \"Spread\": -6.5, \"Home\": False},\n",
    "    \"Colorado\": {\"opponent\": \"Marquette\", \"Over/Under\": 150.5, \"Spread\": -4.5, \"Home\": False},\n",
    "    \"San_Diego_State\": {\"opponent\": \"UConn\", \"Over/Under\": 136.5, \"Spread\": -12.0, \"Home\": False},\n",
    "    \"Iowa_State\": {\"opponent\": \"Illinois\", \"Over/Under\": 147.0, \"Spread\": -1.5, \"Home\": True},\n",
    "    \"Houston\": {\"opponent\": \"Duke\", \"Over/Under\": 134.0, \"Spread\": -4.5, \"Home\": True},\n",
    "    \"Marquette\": {\"opponent\": \"NC_State\", \"Over/Under\": 151.5, \"Spread\": -7.5, \"Home\": True},\n",
    "    \"Illinois\": {\"opponent\": \"UConn\", \"Over/Under\": 154.5, \"Spread\": -8.0, \"Home\": False},\n",
    "    \"Duke\": {\"opponent\": \"NC_State\", \"Over/Under\": 142.0, \"Spread\": -7.0, \"Home\": True},\n",
    "    \"Howard\": {\"opponent\": \"Wagner\", \"Over/Under\": 128.0, \"Spread\": -3.0, \"Home\": True},\n",
    "    \"Virginia\": {\"opponent\": \"Colorado_St\", \"Over/Under\": 121.0, \"Spread\": +3.0, \"Home\": True},\n",
    "    \"Montana_State\": {\"opponent\": \"Grambling\", \"Over/Under\": 134.5, \"Spread\": -4.5, \"Home\": True},\n",
    "    \"Boise_St\": {\"opponent\": \"Colorado\", \"Over/Under\": 142.5, \"Spread\": +3.5, \"Home\": True},\n",
    "    \"Wagner\": {\"opponent\": \"North Carolina\", \"Over/Under\": 133.5, \"Spread\": -20.5, \"Home\": False},\n",
    "    \"Mississippi_St\": {\"opponent\": \"Michigan_State\", \"Over/Under\": 130.5, \"Spread\": +1.5, \"Home\": True},\n",
    "    \"Saint_Mary's\": {\"opponent\": \"Grand_Canyon\", \"Over/Under\": 132.0, \"Spread\": -5.5, \"Home\": True},\n",
    "    \"Charleston\": {\"opponent\": \"Alabama\", \"Over/Under\": 172.5, \"Spread\": -8.5, \"Home\": False},\n",
    "    \"New_Mexico\": {\"opponent\": \"Clemson\", \"Over/Under\": 153.0, \"Spread\": +2.0, \"Home\": False},\n",
    "    \"Colgate\": {\"opponent\": \"Baylor\", \"Over/Under\": 137.5, \"Spread\": -14.5, \"Home\": False},\n",
    "    \"Nevada\": {\"opponent\": \"Dayton\", \"Over/Under\": 137.0, \"Spread\": +1.5, \"Home\": False},\n",
    "    \"Long_Beach_St\": {\"opponent\": \"Arizona\", \"Over/Under\": 163.5, \"Spread\": -20.0, \"Home\": False},\n",
    "    \"Grambling\": {\"opponent\": \"Purdue\", \"Over/Under\": 138.0, \"Spread\": -27.0, \"Home\": False},\n",
    "    \"TCU\": {\"opponent\": \"Utah_State\", \"Over/Under\": 149.5, \"Spread\": +4.0, \"Home\": False},\n",
    "    \"McNeese\": {\"opponent\": \"Gonzaga\", \"Over/Under\": 149.0, \"Spread\": -6.5, \"Home\": False},\n",
    "    \"Samford\": {\"opponent\": \"Kansas\", \"Over/Under\": 152.5, \"Spread\": -7.5, \"Home\": False},\n",
    "    \"South_Carolina\": {\"opponent\": \"Oregon\", \"Over/Under\": 136.0, \"Spread\": +2.5, \"Home\": True},\n",
    "    \"Akron\": {\"opponent\": \"Creighton\", \"Over/Under\": 143.0, \"Spread\": -12.0, \"Home\": False},\n",
    "    \"Colorado_St\": {\"opponent\": \"Texas\", \"Over/Under\": 143.5, \"Spread\": -3.0, \"Home\": False},\n",
    "    \"Saint_Peter's\": {\"opponent\": \"Tennessee\", \"Over/Under\": 130.5, \"Spread\": -22.0, \"Home\": False},\n",
    "    \"Michigan_State\": {\"opponent\": \"North Carolina\", \"Over/Under\": 145.5, \"Spread\": -27.5, \"Home\": False},\n",
    "    \"Grand_Canyon\": {\"opponent\": \"Alabama\", \"Over/Under\": 173.0, \"Spread\": -6.0, \"Home\": False},\n",
    "    \"Baylor\": {\"opponent\": \"Clemson\", \"Over/Under\": 145.5, \"Spread\": -4.5, \"Home\": True},\n",
    "    \"Dayton\": {\"opponent\": \"Arizona\", \"Over/Under\": 148.5, \"Spread\": -8.5, \"Home\": False},\n",
    "    \"Utah_State\": {\"opponent\": \"Purdue\", \"Over/Under\": 150.5, \"Spread\": -11.5, \"Home\": False},\n",
    "    \"Kansas\": {\"opponent\": \"Gonzaga\", \"Over/Under\": 154.0, \"Spread\": +6.0, \"Home\": True},\n",
    "    \"Oregon\": {\"opponent\": \"Creighton\", \"Over/Under\": 148.0, \"Spread\": -3.5, \"Home\": False},\n",
    "    \"Texas\": {\"opponent\": \"Tennessee\", \"Over/Under\": 144.5, \"Spread\": -6.5, \"Home\": False},\n",
    "    \"Arizona\": {\"opponent\": \"Clemson\", \"Over/Under\": 152.5, \"Spread\": -7.0, \"Home\": True},\n",
    "    \"Gonzaga\": {\"opponent\": \"Purdue\", \"Over/Under\": 155.5, \"Spread\": -4.5, \"Home\": False},\n",
    "    \"Creighton\": {\"opponent\": \"Tennessee\", \"Over/Under\": 146.5, \"Spread\": -3.5, \"Home\": False},\n",
    "    \"Clemson\": {\"opponent\": \"Alabama\", \"Over/Under\": 162.5, \"Spread\": -3.5, \"Home\": False},\n",
    "    \"Tennessee\": {\"opponent\": \"Purdue\", \"Over/Under\": 148.0, \"Spread\": -3.0, \"Home\": False},\n",
    "    \"Alabama\": {\"opponent\": \"UConn\", \"Over/Under\": 160.5, \"Spread\": -10.0, \"Home\": False},\n",
    "    \"NC_State\": {\"opponent\": \"Purdue\", \"Over/Under\": 146.5, \"Spread\": -9.5, \"Home\": False},\n",
    "    \"Purdue\": {\"opponent\": \"UConn\", \"Over/Under\": 143.0, \"Spread\": -7.0, \"Home\": False},\n",
    "    \"UConn\": {\"opponent\": \"Purdue\", \"Over/Under\": 143.0, \"Spread\": -7.0, \"Home\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b12448-a254-4500-a1a5-62f036e95161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard betting payout calculation (assuming -110 odds which is typical for over/under)\n",
    "def calculate_payout(bet, is_win):\n",
    "    if is_win:\n",
    "        return bet + (bet * (100/110))  # Win amount (original bet + profit)\n",
    "    else:\n",
    "        return 0  # Loss amount\n",
    "\n",
    "def calculate_over_under_return(game_odds, game_preds, bet_amount, strategy=\"over\", win_rate=0.5):\n",
    "    total_games = len(game_odds)\n",
    "    total_investment = 0\n",
    "    total_return = 0\n",
    "    num_wins, num_losses = 0, 0\n",
    "    \n",
    "    for team, data in game_odds.items():\n",
    "        if team in game_preds:\n",
    "            total_investment += bet_amount\n",
    "            real_away, real_home, away_score, home_score = game_preds[team]\n",
    "            real_total = real_away + real_home\n",
    "            pred_total = away_score + home_score\n",
    "    \n",
    "            over_under_line = data[\"Over/Under\"]\n",
    "            if pred_total < over_under_line:\n",
    "                if real_total < over_under_line:\n",
    "                    num_wins += 1\n",
    "                    payout = calculate_payout(bet_amount, True)\n",
    "                else:\n",
    "                    payout = 0\n",
    "                    num_losses += 1\n",
    "            else:\n",
    "                if real_total < over_under_line:\n",
    "                    payout = 0\n",
    "                    num_losses += 1\n",
    "                else:\n",
    "                    num_wins += 1\n",
    "                    payout = calculate_payout(bet_amount, True)\n",
    "            \n",
    "            total_return += payout\n",
    "    \n",
    "    # Calculate profit/loss and ROI\n",
    "    profit_loss = total_return - total_investment\n",
    "    roi = (profit_loss / total_investment) * 100 if total_investment > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"total_games\": total_games,\n",
    "        \"total_investment\": total_investment,\n",
    "        \"total_return\": total_return,\n",
    "        \"num_wins\": num_wins,\n",
    "        \"num_losses\": num_losses,\n",
    "        \"profit_loss\": profit_loss,\n",
    "        \"roi\": roi\n",
    "    }\n",
    "\n",
    "def calculate_spread_return(game_odds, game_preds, bet_amount):\n",
    "    total_games = 0\n",
    "    total_investment = 0\n",
    "    total_return = 0\n",
    "    num_wins, num_losses = 0, 0\n",
    "    \n",
    "    for team, data in game_odds.items():\n",
    "        if team in game_preds:\n",
    "            total_games += 1\n",
    "            total_investment += bet_amount\n",
    "            home_spread = data[\"Spread\"]\n",
    "            if data[\"Home\"]:\n",
    "                real_home, real_away, pred_home, pred_away = game_preds[team]\n",
    "            else:\n",
    "                real_away, real_home, pred_away, pred_home = game_preds[team]\n",
    "\n",
    "            actual_diff = real_home - real_away\n",
    "            home_covered = actual_diff > -home_spread\n",
    "\n",
    "            pred_diff = pred_home - pred_away\n",
    "            pred_cover = pred_diff > -home_spread\n",
    "\n",
    "            if home_covered == pred_cover:\n",
    "                num_wins += 1\n",
    "                total_return += calculate_payout(bet_amount, True)\n",
    "            else:\n",
    "                num_losses += 1\n",
    "    \n",
    "    # Calculate profit/loss and ROI\n",
    "    profit_loss = total_return - total_investment\n",
    "    roi = (profit_loss / total_investment) * 100 if total_investment > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"total_games\": total_games,\n",
    "        \"total_investment\": total_investment,\n",
    "        \"total_return\": total_return,\n",
    "        \"num_wins\": num_wins,\n",
    "        \"num_losses\": num_losses,\n",
    "        \"profit_loss\": profit_loss,\n",
    "        \"roi\": roi\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685173a-e0d6-4e72-81b8-e44198f0e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_score_at_intervals(pbp_data, interval_seconds=60):\n",
    "    \"\"\"\n",
    "    Sample the game score at regular time intervals\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pbp_data : pandas.DataFrame\n",
    "        Play-by-play data from ncaahoopR\n",
    "    interval_seconds : int\n",
    "        Time interval in seconds to sample the score\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with sampled scores at each time interval\n",
    "    \"\"\"\n",
    "    # Make sure data is sorted by game time (ascending)\n",
    "    # In ncaahoopR, secs_remaining counts down from game start\n",
    "    if 'secs_remaining' in pbp_data.columns:\n",
    "        pbp_data = pbp_data.sort_values('secs_remaining', ascending=False)\n",
    "    \n",
    "    # Regular college basketball game is 40 minutes = 2400 seconds\n",
    "    # Add overtime if needed (each OT is 5 minutes = 300 seconds)\n",
    "    max_time = 2400\n",
    "    if pbp_data['secs_remaining'].min() < 0:\n",
    "        # Game went to overtime\n",
    "        # Calculate how many overtime periods\n",
    "        min_secs = pbp_data['secs_remaining'].min()\n",
    "        ot_periods = abs(min_secs) // 300 + 1\n",
    "        max_time += ot_periods * 300\n",
    "    \n",
    "    # Create time points to sample at\n",
    "    time_points = list(range(0, max_time + interval_seconds, interval_seconds))\n",
    "    \n",
    "    # Initialize results dataframe\n",
    "    results = []\n",
    "    \n",
    "    for time_point in time_points:\n",
    "        # For each time point, find the closest play before that time\n",
    "        elapsed_seconds = time_point\n",
    "        remaining_seconds = 2400 - elapsed_seconds\n",
    "        \n",
    "        # Handle overtime\n",
    "        if remaining_seconds < 0:\n",
    "            # We're in overtime\n",
    "            remaining_seconds_abs = abs(remaining_seconds)\n",
    "        else:\n",
    "            remaining_seconds_abs = remaining_seconds\n",
    "        \n",
    "        # Find the play closest to this time point\n",
    "        # We want the play with the smallest secs_remaining value that's >= our target\n",
    "        closest_plays = pbp_data[pbp_data['secs_remaining'] <= remaining_seconds].sort_values('secs_remaining', ascending=False)\n",
    "        \n",
    "        if len(closest_plays) > 0:\n",
    "            closest_play = closest_plays.iloc[0]\n",
    "            \n",
    "            # Extract the scores at this time point\n",
    "            home_team = closest_play['home']\n",
    "            away_team = closest_play['away']\n",
    "            home_score = closest_play['home_score']\n",
    "            away_score = closest_play['away_score']\n",
    "            \n",
    "            # Add to results\n",
    "            results.append({\n",
    "                'time_elapsed': elapsed_seconds,\n",
    "                'time_remaining': remaining_seconds_abs,\n",
    "                'game_time': format_game_time(elapsed_seconds),\n",
    "                'home_team': home_team,\n",
    "                'away_team': away_team,\n",
    "                'home_score': home_score,\n",
    "                'away_score': away_score,\n",
    "                'score_differential': home_score - away_score\n",
    "            })\n",
    "        else:\n",
    "            # If no play found before this time (e.g., very start of game), use 0-0 score\n",
    "            if len(pbp_data) > 0:\n",
    "                home_team = pbp_data['home'].iloc[0]\n",
    "                away_team = pbp_data['away'].iloc[0]\n",
    "            else:\n",
    "                home_team = \"Home\"\n",
    "                away_team = \"Away\"\n",
    "                \n",
    "            results.append({\n",
    "                'time_elapsed': elapsed_seconds,\n",
    "                'time_remaining': remaining_seconds_abs,\n",
    "                'game_time': format_game_time(elapsed_seconds),\n",
    "                'home_team': home_team,\n",
    "                'away_team': away_team,\n",
    "                'home_score': 0,\n",
    "                'away_score': 0,\n",
    "                'score_differential': 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def format_game_time(elapsed_seconds):\n",
    "    \"\"\"Convert elapsed seconds to game time format (MM:SS)\"\"\"\n",
    "    if elapsed_seconds <= 2400:\n",
    "        # Regulation time\n",
    "        half = 1 if elapsed_seconds <= 1200 else 2\n",
    "        half_elapsed = elapsed_seconds % 1200\n",
    "        minutes = half_elapsed // 60\n",
    "        seconds = half_elapsed % 60\n",
    "        return f\"H{half} {minutes:02d}:{seconds:02d}\"\n",
    "    else:\n",
    "        # Overtime\n",
    "        ot_elapsed = elapsed_seconds - 2400\n",
    "        ot_period = ot_elapsed // 300 + 1\n",
    "        period_elapsed = ot_elapsed % 300\n",
    "        minutes = period_elapsed // 60\n",
    "        seconds = period_elapsed % 60\n",
    "        return f\"OT{ot_period} {minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "def extract_all_games_for_team(data_directory, team_name, interval_seconds=15):\n",
    "    \"\"\"\n",
    "    Extract scores for all games of a specific team from ncaahoopR_data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_directory : str\n",
    "        Path to the ncaahoopR_data directory\n",
    "    team_name : str\n",
    "        The team name to extract scores for\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing game information and scores\n",
    "    \"\"\"\n",
    "    # Load the team's schedule to get game IDs\n",
    "    schedule_path = os.path.join(data_directory, \"schedules\", f\"{team_name}_schedule.csv\")\n",
    "    if not os.path.exists(schedule_path):\n",
    "        raise ValueError(f\"Schedule for {team_name} not found at {schedule_path}\")\n",
    "    \n",
    "    schedule = pd.read_csv(schedule_path)\n",
    "    \n",
    "    # Create a results dataframe\n",
    "    results = []\n",
    "    \n",
    "    # Process each game in the schedule\n",
    "    for _, game in schedule.iterrows():\n",
    "        game_id = game['game_id']\n",
    "        \n",
    "        # Look for the play-by-play file\n",
    "        pbp_path = os.path.join(data_directory, \"pbp_logs\", \"**\", f\"{game_id}.csv\")\n",
    "        pbp_files = glob.glob(pbp_path, recursive=True)\n",
    "        \n",
    "        if not pbp_files:\n",
    "            print(f\"PBP data for game {game_id} not found\")\n",
    "            continue\n",
    "            \n",
    "        # Load the play-by-play data\n",
    "        pbp_data = pd.read_csv(pbp_files[0])\n",
    "        \n",
    "        # Extract the score\n",
    "        sampled_scores = sample_score_at_intervals(pbp_data, interval_seconds=interval_seconds)\n",
    "        \n",
    "        results.append(sampled_scores)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776bc60-c2b5-4828-8c33-17d7f1a2549b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"./ncaahoopR_data/2023-24/\"\n",
    "team = \"Michigan\"\n",
    "\n",
    "# Extract scores for all games for the team\n",
    "team_results = extract_all_games_for_team(data_dir, team)\n",
    "\n",
    "print(team_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242a328-2195-4855-b026-593cbae9d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_scores(pbp, target_school):\n",
    "    if pbp['home_team'].to_numpy()[0] == target_school:\n",
    "        target_score = 'home_score'\n",
    "        other_score = 'away_score'\n",
    "        other_team = pbp['away_team'].to_numpy()[0]\n",
    "    else:\n",
    "        if pbp['away_team'].to_numpy()[0] != target_school: assert ValueError()\n",
    "        target_score = 'away_score'\n",
    "        other_score = 'home_score'\n",
    "        other_team = pbp['home_team'].to_numpy()[0]\n",
    "\n",
    "    return pbp[target_score].to_numpy(), pbp[other_score].to_numpy(), other_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b797d-a8d2-4e58-9dba-bc652a48435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_interval_scores(data_dir, target_team, interval_seconds=30):\n",
    "    all_target_scores = []\n",
    "    all_other_scores = []\n",
    "    other_teams = []\n",
    "\n",
    "    team_results = extract_all_games_for_team(data_dir, target_team, interval_seconds=interval_seconds)\n",
    "    \n",
    "    for pbp in team_results:\n",
    "        new_targ, new_other, new_team = attribute_scores(pbp, target_team)\n",
    "\n",
    "        all_target_scores.append(new_targ)\n",
    "        all_other_scores.append(new_other)\n",
    "        other_teams.append(new_team)\n",
    "\n",
    "    return np.array(all_target_scores), np.array(all_other_scores), other_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb1947-9a80-4552-8576-3fb1009db9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def autoreg_lr(team_name, T, interval_seconds, lag, plot=False, print_model=False):\n",
    "    team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, team_name, interval_seconds=interval_seconds)\n",
    "    team_score = np.diff(team_scores[-1])\n",
    "    opponent_score = np.diff(opponent_scores[-1])\n",
    "    \n",
    "    # Calculate score differences\n",
    "    score_diff = np.array([a - b for a, b in zip(team_score, opponent_score)])\n",
    "    \n",
    "    # Create a DataFrame to organize data\n",
    "    df = pd.DataFrame({\n",
    "        'TeamA': team_score,\n",
    "        'TeamB': opponent_score,\n",
    "        'ScoreDiff': score_diff\n",
    "    })\n",
    "    \n",
    "    # Define a function to prepare data for ARMA model\n",
    "    def prepare_arma_data(team_a, team_b, diff, start, end, lag=4, target_team='A'):\n",
    "        \"\"\"\n",
    "        Prepare data for ARMA model with specified lag\n",
    "        \"\"\"\n",
    "        # Create empty lists to store features and target\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        # Loop through the data starting from position where we have enough history\n",
    "        for i in range(max(lag, start), end):\n",
    "            # Get target value (current score for Team A)\n",
    "            if target_team == 'A':\n",
    "                target = team_a[i]\n",
    "            else:\n",
    "                target = team_b[i]\n",
    "            \n",
    "            # Get features: last 'lag' scores for Team A, Team B, and their differences\n",
    "            features = []\n",
    "            for j in range(1, lag+1):\n",
    "                features.append(team_a[i-j])  # Team A previous scores\n",
    "            \n",
    "            for j in range(1, lag+1):\n",
    "                features.append(team_b[i-j])  # Team B previous scores\n",
    "                \n",
    "            for j in range(1, lag+1):\n",
    "                features.append(diff[i-j])  # Previous score differences\n",
    "            \n",
    "            # Add to our dataset\n",
    "            X.append(features)\n",
    "            y.append(target)\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    # Prepare data for ARMA model using last 4 scores\n",
    "    X, y = prepare_arma_data(team_score, opponent_score, score_diff, 0, T//2, lag=lag)\n",
    "    \n",
    "    team_model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    opp_X, opp_y = prepare_arma_data(team_score, opponent_score, score_diff, 0, T//2, lag=lag, target_team='B')\n",
    "    opp_model = LinearRegression()\n",
    "    opp_model.fit(opp_X, opp_y)\n",
    "\n",
    "    if print_model:\n",
    "        # Print model coefficients\n",
    "        print(\"Intercept:\", model.intercept_)\n",
    "        print(\"Coefficients for features:\")\n",
    "        feature_names = (\n",
    "            [f\"TeamA_lag{j}\" for j in range(1, lag + 1)] + \n",
    "            [f\"TeamB_lag{j}\" for j in range(1, lag + 1)] + \n",
    "            [f\"ScoreDiff_lag{j}\" for j in range(1, lag + 1)]\n",
    "        )\n",
    "        for name, coef in zip(feature_names, model.coef_):\n",
    "            print(f\"  {name}: {coef:.4f}\")\n",
    "    \n",
    "    # Make a prediction for the second half of the game\n",
    "    test_X, test_y = prepare_arma_data(team_score, opponent_score, score_diff, T//2, T, lag=lag)\n",
    "    \n",
    "    # second_half_predictions = model.predict(test_X)\n",
    "    \n",
    "    # For a fully autoregressive model using only predictions (no actual values after training)\n",
    "    train_end = T//2\n",
    "    actual_scores = team_score[T//2:T].copy()\n",
    "    predicted_scores = np.zeros_like(actual_scores)\n",
    "    \n",
    "    fully_ar_predicted = [0 for _ in range(len(predicted_scores))]\n",
    "    opp_fully_ar_predicted = [0 for _ in range(len(predicted_scores))]\n",
    "    \n",
    "    # Initialize history with training data\n",
    "    ar_team_a = team_score[:train_end].tolist()\n",
    "    ar_team_b = opponent_score[:train_end].tolist()\n",
    "    ar_diff = score_diff[:train_end].tolist()\n",
    "    \n",
    "    # Generate predictions using only the model's own predictions\n",
    "    for i in range(len(actual_scores)):\n",
    "        # Prepare features for the next prediction\n",
    "        features = []\n",
    "        for j in range(1, lag+1):\n",
    "            features.append(ar_team_a[-j])\n",
    "        for j in range(1, lag+1):\n",
    "            features.append(ar_team_b[-j])\n",
    "        for j in range(1, lag+1):\n",
    "            features.append(ar_diff[-j])\n",
    "    \n",
    "        # Make prediction for the next step\n",
    "        next_prediction = model.predict(np.array([features]))[0]\n",
    "        fully_ar_predicted[i] = next_prediction\n",
    "    \n",
    "        opp_prediction = opp_model.predict(np.array([features]))[0]\n",
    "        opp_fully_ar_predicted[i] = opp_prediction\n",
    "        \n",
    "        # Update history with the prediction for the next iteration\n",
    "        ar_team_a.append(next_prediction)\n",
    "        # Assuming we have the opponent's true score (in a real game this would be observed)\n",
    "        ar_team_b.append(opp_prediction)\n",
    "        ar_diff.append(next_prediction - opp_prediction)\n",
    "\n",
    "    if plot:\n",
    "        # Plot full autoregressive results\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(len(actual_scores)), np.cumsum(actual_scores), 'bo-', label='Actual Team A Scores')\n",
    "        plt.plot(range(len(fully_ar_predicted)), np.cumsum(fully_ar_predicted), 'go-', label='Fully Autoregressive Predictions')\n",
    "        plt.xlabel('Time Index')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Fully Autoregressive Model: Actual vs Predicted Team A Scores')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    complete_pred_team_a_series = np.hstack([team_score[:train_end], fully_ar_predicted])\n",
    "    complete_pred_team_b_series = np.hstack([opponent_score[:train_end], opp_fully_ar_predicted])\n",
    "\n",
    "    return [complete_pred_team_a_series, complete_pred_team_b_series], [team_score, opponent_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2936e84-003c-4bce-a968-215606e5b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors_multivariate_lr(team_name, T, interval_seconds, lag):\n",
    "    pred_series, true_series = autoreg_lr(team_name, T, interval_seconds, lag)\n",
    "    half_T = T//2\n",
    "\n",
    "    pred_series = [reconstruct_score(true_series[0], pred_series[0], half_T), reconstruct_score(true_series[1], pred_series[1], half_T)]\n",
    "    true_series = [np.cumsum(true_series[0]), np.cumsum(true_series[1])]\n",
    "\n",
    "    team_score_err = np.abs(pred_series[0][-1] - true_series[0][-1])\n",
    "    opp_score_err = np.abs(pred_series[1][-1] - true_series[1][-1])\n",
    "    total_err = np.abs((pred_series[0][-1] + pred_series[1][-1]) - (true_series[0][-1] + true_series[1][-1]))\n",
    "    return team_score_err, opp_score_err, total_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda2569-b2d3-482e-94f1-56393cc950f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find best lag\n",
    "lag_team_errs, lag_opp_errs, lag_total_errs = [], [], []\n",
    "all_lag_team_errs, all_lag_opp_errs, all_lag_total_errs = [], [], []\n",
    "for lag in [1, 2, 3, 4]:\n",
    "    team_errs, opp_errs, total_errs = [], [], []\n",
    "    for team_name in tqdm(TOURNAMENT_TEAMS):\n",
    "        new_team_err, new_opp_err, new_total_err = get_errors_multivariate_lr(team_name, 100, 24, lag)\n",
    "    \n",
    "        team_errs.append(new_team_err)\n",
    "        opp_errs.append(new_opp_err)\n",
    "        total_errs.append(new_total_err)\n",
    "\n",
    "    lag_team_errs.append(np.mean(team_errs))\n",
    "    lag_opp_errs.append(np.mean(opp_errs))\n",
    "    lag_total_errs.append(np.mean(total_errs))\n",
    "\n",
    "    all_lag_team_errs.append(team_errs)\n",
    "    all_lag_opp_errs.append(opp_errs)\n",
    "    all_lag_total_errs.append(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eabcef-4ed8-47d9-9f21-eac0607859b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_team_errs[1], np.std(all_lag_team_errs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfb3f0-bfb3-4895-9253-181bf5f5ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_opp_errs[1], np.std(all_lag_opp_errs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324d4e1-e8ee-4584-8cac-f6cadd3f9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_total_errs[1], np.std(all_lag_total_errs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0273aeda-19cf-4fca-858f-b1ce96c91745",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 3, 4]\n",
    "plt.plot(lags, lag_team_errs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce0bea-0b30-4ca6-bc70-cb69f1572b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 3, 4]\n",
    "plt.plot(lags, lag_opp_errs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02438e79-1f8a-4634-8f2b-8137db5ff260",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 3, 4]\n",
    "plt.plot(lags, lag_total_errs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f318f-fc28-43d4-882a-8f273fe6ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_box_whisker_plot(data_lists, labels=None, title=\"Box and Whisker Plot\", \n",
    "                           xlabel=\"Categories\", ylabel=\"Values\"):\n",
    "    \"\"\"\n",
    "    Create a box and whisker plot from a list of lists.\n",
    "    \n",
    "    Parameters:\n",
    "    data_lists (list): A list where each element is a list of numerical values\n",
    "    labels (list): Optional list of labels for each box\n",
    "    title (str): Title of the plot\n",
    "    xlabel (str): Label for x-axis\n",
    "    ylabel (str): Label for y-axis\n",
    "    \n",
    "    Returns:\n",
    "    fig, ax: The figure and axes objects\n",
    "    \"\"\"\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Create the box plot\n",
    "    box_plot = ax.boxplot(data_lists)\n",
    "    \n",
    "    # Add grid lines\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add labels if provided\n",
    "    if labels:\n",
    "        ax.set_xticklabels(labels)\n",
    "    \n",
    "    # Add title and labels\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf0b8f-c874-46a0-b433-e4cb53b13daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_box_whisker_plot(all_lag_opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdeba72-4da6-4f24-bdc4-f12fb66775f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(lag_team_errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6143e2-52b8-46e0-901d-62207ddb84ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200acb2-e021-434d-9fae-898a2a89a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "# ------------------------\n",
    "# 1. Linear Regression with ARMA for De-trended Data\n",
    "# ------------------------\n",
    "\n",
    "def select_best_arma_model(data, p_range=(0, 5), q_range=(0, 5)):\n",
    "    \"\"\"\n",
    "    Select the best ARMA(p, q) model for the given data based on AIC.\n",
    "    \"\"\"\n",
    "    best_aic = np.inf\n",
    "    best_order = None\n",
    "    best_model = None\n",
    "\n",
    "    for p in range(p_range[0], p_range[1] + 1):\n",
    "        for q in range(q_range[0], q_range[1] + 1):\n",
    "            if p == 0 and q == 0:\n",
    "                continue\n",
    "            try:\n",
    "                model = ARIMA(data, order=(p, 0, q)).fit()\n",
    "                if model.aic < best_aic:\n",
    "                    best_aic = model.aic\n",
    "                    best_order = (p, 0, q)\n",
    "                    best_model = model\n",
    "            except:\n",
    "                continue\n",
    "    return best_model, best_order\n",
    "\n",
    "def linear_regression_prediction(team_scores, opponent_scores, half_index, extract_trend=False, predict_full_game=False):\n",
    "    \"\"\"\n",
    "    Use linear regression + ARMA to predict second half scores.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    team_scores : array-like\n",
    "        Scores of the team across timesteps (quarters/minutes)\n",
    "    opponent_scores : array-like\n",
    "        Scores of the opponent across timesteps\n",
    "    half_index : int\n",
    "        Index that separates first and second half\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    team_predictions : array-like\n",
    "        Predicted team scores for second half\n",
    "    opponent_predictions : array-like\n",
    "        Predicted opponent scores for second half\n",
    "    \"\"\"\n",
    "    # Extract the first half data\n",
    "    first_half_team = np.array(team_scores[:-half_index])\n",
    "    first_half_indexes = np.arange(len(first_half_team)-half_index)\n",
    "    first_half_opp = np.array(opponent_scores[:-half_index])\n",
    "        \n",
    "    second_half_indexes = np.arange(half_index, half_index*2)\n",
    "\n",
    "    if extract_trend:\n",
    "        # Fit linear trend for team scores\n",
    "        print(first_half_indexes.shape, first_half_team.shape)\n",
    "        team_reg = LinearRegression().fit(first_half_indexes.reshape(-1, 1), first_half_team)\n",
    "        \n",
    "        # Get the linear trend\n",
    "        team_trend = team_reg.predict(first_half_indexes.reshape(-1, 1))\n",
    "    \n",
    "        # De-trend the data\n",
    "        team_detrended = first_half_team - team_trend\n",
    "    else:\n",
    "        team_detrended = first_half_team\n",
    "    \n",
    "    # Fit ARMA model to de-trended data\n",
    "    # Note: Order selection (p,d,q) should be determined by AIC/BIC in practice\n",
    "    team_arma_model, team_order = select_best_arma_model(team_detrended)\n",
    "\n",
    "    if extract_trend:\n",
    "        # Do the same for opponent\n",
    "        opp_reg = LinearRegression().fit(first_half_indexes.reshape(-1, 1), first_half_opp)\n",
    "        opp_trend = opp_reg.predict(first_half_indexes.reshape(-1, 1))\n",
    "        opp_detrended = first_half_opp - opp_trend\n",
    "    else:\n",
    "        opp_detrended = first_half_opp\n",
    "        \n",
    "    opp_arma_model, opp_order = select_best_arma_model(opp_detrended)\n",
    "\n",
    "    print(f\"{team_order=}, {opp_order=}\")\n",
    "\n",
    "    # Predict de-trended values for second half\n",
    "    team_detrended_forecast = team_arma_model.forecast(steps=len(second_half_indexes))\n",
    "    opp_detrended_forecast = opp_arma_model.forecast(steps=len(second_half_indexes))\n",
    "\n",
    "    if extract_trend:\n",
    "        # Predict trend component for second half\n",
    "        team_trend_forecast = team_reg.predict(second_half_indexes.reshape(-1, 1))\n",
    "        opp_trend_forecast = opp_reg.predict(second_half_indexes.reshape(-1, 1))\n",
    "        \n",
    "        # Combine trend and ARMA components\n",
    "        team_predictions = team_trend_forecast + team_detrended_forecast\n",
    "        opp_predictions = opp_trend_forecast + opp_detrended_forecast\n",
    "    else:\n",
    "        if predict_full_game:\n",
    "            team_predictions = team_detrended_forecast\n",
    "            opp_predictions = opp_detrended_forecast\n",
    "        else:\n",
    "            team_predictions = np.hstack((first_half_team[-half_index * 2:-half_index], team_detrended_forecast))\n",
    "            opp_predictions = np.hstack((first_half_opp[-half_index * 2:-half_index], opp_detrended_forecast))\n",
    "    \n",
    "    return team_predictions, opp_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f60b2f-1e94-4e28-a20f-c26a0ca6677a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, 'UConn', interval_seconds=24)\n",
    "half_index = 50\n",
    "team_scores = np.diff(team_scores)\n",
    "opponent_scores = np.diff(opponent_scores)\n",
    "\n",
    "target_team_score, target_opponent_score = team_scores.flatten(), opponent_scores.flatten()\n",
    "\n",
    "pred_series = linear_regression_prediction(target_team_score, target_opponent_score, half_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabcb93-01f7-44ec-9e51-92e6ba254508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# First subplot: original scores\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.cumsum(team_scores[-1]), label='UConn Score Cumulative', color='blue')\n",
    "plt.plot(np.cumsum(opponent_scores[-1]), label='Purdue Score Cumulative', color='black')\n",
    "\n",
    "plt.axvline(half_index, color='gray', linestyle=':', label='Halftime')\n",
    "plt.title(\"Cumulative/Original Scores\")\n",
    "plt.legend(loc=2)\n",
    "\n",
    "# Second subplot: cumulative sum\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(team_scores[-1], label='UConn Score', color='blue')\n",
    "plt.plot(opponent_scores[-1], label='Purdue Score', color='black')\n",
    "\n",
    "plt.axvline(half_index, color='gray', linestyle=':', label='Halftime')\n",
    "plt.title(\"First Order Differenced Scores\")\n",
    "plt.legend(loc=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('OriginalScorePlots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae52a2-7312-44c3-96a4-d92a11b8e6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33897784-46b0-415d-802b-3c868f70b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_team_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0bc704-ff66-4599-b2cf-bf09a6c7254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_last_game_lr(data_dir, team_name, interval_seconds=24, T=100, to_fill_zeros=False, predict_full_game=False):\n",
    "    team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, team_name, interval_seconds=interval_seconds)\n",
    "    half_index = T//2\n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    \n",
    "    target_team_score, target_opponent_score = team_scores.flatten(), opponent_scores.flatten()\n",
    "    \n",
    "    pred_series = linear_regression_prediction(\n",
    "        target_team_score, target_opponent_score, \n",
    "        half_index * 2 if predict_full_game else half_index,\n",
    "        predict_full_game=predict_full_game\n",
    "    )\n",
    "    \n",
    "    return pred_series, [target_team_score[-half_index*2:], target_opponent_score[-half_index*2:]]\n",
    "\n",
    "def plot_forecast(pred_series, true_series, half_T=50, diff_score=True, school_name=''):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    labels = [f'{school_name} Home Score', 'Away Score']\n",
    "    for i in range(2):\n",
    "        plt.subplot(2, 1, i+1)\n",
    "        if diff_score:\n",
    "            plt.plot(true_series[i], label='True', color='black')\n",
    "            plt.plot(pred_series[i], '--', label='Forecast', color='blue')\n",
    "        else:\n",
    "            plt.plot(np.cumsum(true_series[i]), label='True', color='black')\n",
    "            plt.plot(reconstruct_score(true_series[i], pred_series[i], half_T), '--', label='Forecast', color='blue')\n",
    "        plt.axvline(half_T, color='gray', linestyle=':', label='Forecast Start')\n",
    "        plt.title(labels[i])\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8665f266-7adb-4418-b4fa-8f1a56b1ebd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e546708-2fa8-481a-935b-ff62fb89edfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848ed67-5a9f-458a-bbee-0c02f6681395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d713f79-bfe9-42c1-ac11-7c1d56ee5d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_name = 'Michigan'\n",
    "pred_series, true_series = predict_last_game_lr(data_dir, team_name, predict_full_game=True)\n",
    "plot_forecast(pred_series, true_series)\n",
    "plot_forecast(pred_series, true_series, diff_score=False, full_game_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131ef04-11e1-4a7b-b8a3-485875d04d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_name = 'Kentucky'\n",
    "pred_series, true_series = predict_last_game_lr(data_dir, team_name, predict_full_game=True)\n",
    "plot_forecast(pred_series, true_series)\n",
    "plot_forecast(pred_series, true_series, diff_score=False, full_game_pred=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df98c1d-0c58-41ed-9bb0-38138f54f6a6",
   "metadata": {},
   "source": [
    "## LR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f06d80-8891-49d6-9035-c9f664113165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors_lr(team_name):\n",
    "    pred_series, true_series = predict_last_game_lr(data_dir, team_name)\n",
    "    half_T = 50\n",
    "\n",
    "    pred_series = [reconstruct_score(true_series[0], pred_series[0], half_T), reconstruct_score(true_series[1], pred_series[1], half_T)]\n",
    "    true_series = [np.cumsum(true_series[0]), np.cumsum(true_series[1])]\n",
    "\n",
    "    team_score_err = np.abs(pred_series[0][-1] - true_series[0][-1])\n",
    "    opp_score_err = np.abs(pred_series[1][-1] - true_series[1][-1])\n",
    "    total_err = np.abs((pred_series[0][-1] + pred_series[1][-1]) - (true_series[0][-1] + true_series[1][-1]))\n",
    "    return team_score_err, opp_score_err, total_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf1c8ee-f711-4256-a802-6887db4d2fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    new_team_err, new_opp_err, new_total_err = get_errors_lr(team_name)\n",
    "\n",
    "    team_errs.append(new_team_err)\n",
    "    opp_errs.append(new_opp_err)\n",
    "    total_errs.append(new_total_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf2225-5fec-4beb-aac3-9264315028de",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e811af3-8b53-4094-968c-497bcc5acf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96464edc-e0dc-4a22-820d-9b63b83f3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d97820-ca3f-4fd4-b6c8-6b4a78530359",
   "metadata": {},
   "source": [
    "## LR Full Game Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440317d-01e0-4d5a-8faa-a41d6d592fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_game_errors_lr(team_name):\n",
    "    pred_series, true_series = predict_last_game_lr(data_dir, team_name, predict_full_game=True)\n",
    "    half_T = 50\n",
    "\n",
    "    pred_series = [np.cumsum(pred_series[0]), np.cumsum(pred_series[1])]\n",
    "    true_series = [np.cumsum(true_series[0]), np.cumsum(true_series[1])]\n",
    "\n",
    "    team_score_err = np.abs(pred_series[0][-1] - true_series[0][-1])\n",
    "    opp_score_err = np.abs(pred_series[1][-1] - true_series[1][-1])\n",
    "    total_err = np.abs((pred_series[0][-1] + pred_series[1][-1]) - (true_series[0][-1] + true_series[1][-1]))\n",
    "    \n",
    "    actual = true_series[0][-1]\n",
    "    opp_actual = true_series[1][-1]\n",
    "    team_pred = pred_series[0][-1]\n",
    "    opp_pred = pred_series[1][-1]\n",
    "    return team_score_err, opp_score_err, total_err, actual, opp_actual, team_pred, opp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a7ef7-b439-416e-a2c1-f4cc88dd451b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_pred = {}\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    new_team_err, new_opp_err, new_total_err, actual, opp_actual, team_pred, opp_pred = get_full_game_errors_lr(team_name)\n",
    "\n",
    "    team_errs.append(new_team_err)\n",
    "    opp_errs.append(new_opp_err)\n",
    "    total_errs.append(new_total_err)\n",
    "\n",
    "    team_to_pred[team_name] = (actual, opp_actual, team_pred, opp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f3b0a-78e9-466e-bdea-58fba09d2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb796886-aaac-4aeb-8666-596f8ccc57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34b463-6e0d-4696-ba98-d799a943ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58f800-8120-461d-bf65-7fc10a74ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992204e-bd76-4000-8999-77a223b52c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5ae20-9212-4278-8081-72380954157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_over_under_return(game_odds, team_to_pred, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555cbb9-d3de-4b97-b7a5-e5a9bddf7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_spread_return(game_odds, team_to_pred, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6860005-d01f-446b-962c-4c6b8c778fe3",
   "metadata": {},
   "source": [
    "## mSSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179ef4e-67e1-48e0-992e-83c3ffbb68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_page_matrix(series, L):\n",
    "    T = len(series)\n",
    "    num_pages = T//L\n",
    "    series_trimmed = series[:num_pages * L]\n",
    "    page_matrix = series_trimmed.reshape(num_pages, L)\n",
    "    return page_matrix\n",
    "\n",
    "def make_wide_matrices(all_games, T, use_all_data=False):\n",
    "    L = int(np.sqrt(T))\n",
    "    target_wide, opp_wide = [], []\n",
    "    for game_ind, (home_series, opp_series) in enumerate(all_games):\n",
    "        target_wide.append(make_page_matrix(home_series, L))\n",
    "        opp_wide.append(make_page_matrix(opp_series, L))\n",
    "        if use_all_data:\n",
    "            if game_ind != len(all_games)-1:\n",
    "                target_wide.append(make_page_matrix(opp_series, L))\n",
    "                opp_wide.append(make_page_matrix(home_series, L))\n",
    "\n",
    "    return np.hstack(target_wide), np.hstack(opp_wide)\n",
    "\n",
    "def get_energy_percentile(singular_values, rank):\n",
    "    total_energy = np.sum([s**2 for s in singular_values])\n",
    "    retained_energy = np.sum([s**2 for s in singular_values[:rank]])\n",
    "    return retained_energy/total_energy\n",
    "\n",
    "def get_important_rank(singular_values):\n",
    "    for r_tilde in range(1, len(singular_values)):\n",
    "        energy_ratio = get_energy_percentile(\n",
    "            singular_values, \n",
    "            r_tilde\n",
    "        )\n",
    "        if energy_ratio > 0.9:\n",
    "            return r_tilde\n",
    "\n",
    "def finish_mSSA(target_wide, opp_wide, all_games, T, half_T, use_all_data=False):\n",
    "    target_series = mssa(target_wide, all_games, T, use_all_data=use_all_data)\n",
    "    opp_series = mssa(opp_wide, all_games, T, use_all_data=use_all_data)\n",
    "\n",
    "    return target_series, opp_series\n",
    "\n",
    "def mssa(target_wide, all_games, T, use_all_data=False):\n",
    "    L = int(np.sqrt(T))\n",
    "    half_T = T//2\n",
    "\n",
    "    U, s, VT = np.linalg.svd(target_wide, full_matrices=False)\n",
    "    r = get_important_rank(s)\n",
    "    S_r = np.diag(s[:r])\n",
    "\n",
    "    if use_all_data:\n",
    "        N = len(all_games)\n",
    "    else:\n",
    "        N = len(all_games) * 2 - 1\n",
    "        \n",
    "    scalar = (N * T - half_T)/(N * T)\n",
    "\n",
    "    X_denoised = (U[:, :r] @ S_r @ VT[:r, :]) * (1/scalar)\n",
    "    target_series = X_denoised[:, -(T//L):].flatten()\n",
    "\n",
    "    return target_series\n",
    "\n",
    "def reconstruct_score(ground_truth, reconstructed, half_index):\n",
    "    ground_truth_first_half = np.cumsum(ground_truth[:half_index])\n",
    "    pred_second_half = np.cumsum(reconstructed[half_index:])\n",
    "    pred_second_half += ground_truth_first_half[-1]\n",
    "\n",
    "    return np.hstack((ground_truth_first_half, pred_second_half))\n",
    "\n",
    "def predict_last_game_mssa(\n",
    "    data_dir, team_name, interval_seconds=60, T=40, \n",
    "    to_fill_zeros=False, use_one_matrix=False, seed=10, \n",
    "    predict_full_game=False\n",
    "):\n",
    "    half_T = T//2\n",
    "    \n",
    "    team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, team_name, interval_seconds=interval_seconds)\n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    \n",
    "    # team_scores = np.clip(team_scores, a_min=0, a_max=10)\n",
    "    # opponent_scores = np.clip(opponent_scores, a_min=0, a_max=10)\n",
    "    N = len(team_scores)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    train_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(N-1)])[:, :, :T]\n",
    "    test_game = np.array([team_scores[-1], opponent_scores[-1]])\n",
    "\n",
    "    if predict_full_game:\n",
    "        to_append = np.ones_like(test_game) * np.mean(train_games)\n",
    "        to_append = to_append.reshape((1, 2, T))\n",
    "    else:\n",
    "        test_half = test_game[:, :half_T]\n",
    "        if to_fill_zeros:\n",
    "            fill_in = np.zeros(test_half.shape)\n",
    "        else:\n",
    "            fill_in = np.ones(test_half.shape) * np.mean(train_games)\n",
    "        \n",
    "        to_append = np.hstack((test_half, fill_in)).reshape(1, 2, T)\n",
    "\n",
    "    all_games = np.vstack((train_games, to_append))\n",
    "\n",
    "    target_wide, opp_wide = make_wide_matrices(all_games, T, use_all_data=use_one_matrix)\n",
    "\n",
    "    target_series = finish_mSSA(target_wide, opp_wide, all_games, T, half_T, use_all_data=use_one_matrix)\n",
    "\n",
    "    return target_series, test_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9eba8-104d-47d6-9f47-87a4bb052b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(pred_series, true_series, half_T=50, diff_score=True, school_name='', full_game_pred=False):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    labels = [f'{school_name} Home Score', 'Away Score']\n",
    "    for i in range(2):\n",
    "        plt.subplot(2, 1, i+1)\n",
    "        if diff_score:\n",
    "            plt.plot(true_series[i], label='True', color='black')\n",
    "            plt.plot(pred_series[i], '--', label='Forecast', color='blue')\n",
    "        else:\n",
    "            plt.plot(np.cumsum(true_series[i]), label='True', color='black')\n",
    "            if full_game_pred:\n",
    "                plt.plot(pred_series[i], '--', label='Forecast', color='blue')\n",
    "            else:\n",
    "                plt.plot(reconstruct_score(true_series[i], pred_series[i], half_T), '--', label='Forecast', color='blue')\n",
    "        plt.axvline(half_T, color='gray', linestyle=':', label='Forecast Start')\n",
    "        plt.title(labels[i])\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770319b-eb9b-4259-8d1d-ac5403bcb927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_name = 'Auburn'\n",
    "interval_seconds = 24\n",
    "T = int((40*60)/interval_seconds)\n",
    "half_T = T//2\n",
    "pred_series, true_series = predict_last_game_mssa(\n",
    "    data_dir, team_name, interval_seconds=interval_seconds, T=T, \n",
    "    to_fill_zeros=False, use_one_matrix=False,\n",
    "    predict_full_game=True\n",
    ")\n",
    "plot_forecast(pred_series, true_series, half_T=half_T)\n",
    "plot_forecast(pred_series, true_series, half_T=half_T, diff_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152457a-bdd0-4ace-a4bb-811904efbc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = 'Auburn'\n",
    "interval_seconds = 24\n",
    "T = int((40*60)/interval_seconds)\n",
    "half_T = T//2\n",
    "pred_series, true_series = predict_last_game_mssa(\n",
    "    data_dir, team_name, interval_seconds=interval_seconds, T=T, \n",
    "    to_fill_zeros=False, use_one_matrix=True, seed=1\n",
    ")\n",
    "plot_forecast(pred_series, true_series, half_T=half_T)\n",
    "plot_forecast(pred_series, true_series, half_T=half_T, diff_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc3fe4-0795-46c7-97fb-a12341332076",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "def get_errors_mssa(team_name, T=100, interval_seconds=24, to_fill_zeros=False, use_one_matrix=False):\n",
    "    pred_series, true_series = predict_last_game_mssa(\n",
    "        data_dir, team_name, T=T, \n",
    "        interval_seconds=interval_seconds, \n",
    "        to_fill_zeros=to_fill_zeros,\n",
    "        use_one_matrix=use_one_matrix\n",
    "    )\n",
    "    half_T = T//2\n",
    "    \n",
    "    pred_series = [reconstruct_score(true_series[0], pred_series[0], half_T), reconstruct_score(true_series[1], pred_series[1], half_T)]\n",
    "    true_series = [np.cumsum(true_series[0]), np.cumsum(true_series[1])]\n",
    "\n",
    "    team_score_err = np.abs(pred_series[0][-1] - true_series[0][-1])\n",
    "    opp_score_err = np.abs(pred_series[1][-1] - true_series[1][-1])\n",
    "    total_err = np.abs((pred_series[0][-1] + pred_series[1][-1]) - (true_series[0][-1] + true_series[1][-1]))\n",
    "\n",
    "    actual = true_series[0][-1]\n",
    "    opp_actual = true_series[1][-1]\n",
    "    team_pred = pred_series[0][-1]\n",
    "    opp_pred = pred_series[1][-1]\n",
    "    return team_score_err, opp_score_err, total_err, actual, opp_actual, team_pred, opp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a12a1-3492-4305-81b2-fb4da466309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOURNAMENT_TEAMS = [\n",
    "    # EAST \n",
    "    \"UConn\",\n",
    "    \"Iowa_State\",\n",
    "    \"Illinois\",\n",
    "    \"Auburn\",\n",
    "    \"San_Diego_State\",\n",
    "    \"BYU\",\n",
    "    \"Washington_St\",\n",
    "    \"FAU\",\n",
    "    \"Northwestern\",\n",
    "    \"Drake\",\n",
    "    \"Duquesne\",\n",
    "    \"UAB\",\n",
    "    \"Morehead_State\",\n",
    "    \"South_Dakota_St\",\n",
    "    \"Stetson\",\n",
    "    # WEST\n",
    "    \"NC_Central\",\n",
    "    \"Arizona\",\n",
    "    \"Baylor\",\n",
    "    \"Alabama\",\n",
    "    \"Saint_Mary's\",\n",
    "    \"Clemson\",\n",
    "    \"Dayton\",\n",
    "    \"Miss_St\",\n",
    "    \"Michigan_State\",\n",
    "    \"Nevada\",\n",
    "    \"New_Mexico\",\n",
    "    \"Grand_Canyon\",\n",
    "    \"Charleston\",\n",
    "    \"Colgate\",\n",
    "    \"Long_Beach_State\",\n",
    "    \"Howard\",\n",
    "    \"Wagner\",\n",
    "    #SOUTH\n",
    "    \"Houston\",\n",
    "    \"Marquette\",\n",
    "    \"Kentucky\",\n",
    "    \"Duke\",\n",
    "    \"Wisconsin\",\n",
    "    \"Texas_Tech\",\n",
    "    \"Florida\",\n",
    "    \"Nebraska\",\n",
    "    \"Texas_A&M\",\n",
    "    \"Boise_State\",\n",
    "    \"Colorado\",\n",
    "    \"NC_State\",\n",
    "    \"JMU\",\n",
    "    \"Vermont\",\n",
    "    \"Oakland\",\n",
    "    \"W_Kentucky\",\n",
    "    \"Longwood\",\n",
    "    #MIDWEST\n",
    "    \"Purdue\",\n",
    "    \"Tennessee\",\n",
    "    \"Creighton\",\n",
    "    \"Kansas\",\n",
    "    \"Gonzaga\",\n",
    "    \"South_Carolina\",\n",
    "    \"Texas\",\n",
    "    \"Utah_State\",\n",
    "    \"TCU\",\n",
    "    \"UVA\",\n",
    "    \"Colorado_State\",\n",
    "    \"Oregon\",\n",
    "    \"McNeese\",\n",
    "    \"Samford\",\n",
    "    \"Akron\",\n",
    "    \"St_Peter's\",\n",
    "    \"Montana_State\",\n",
    "    \"Grambling\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae168c44-19ed-4ef8-9f4f-7562af7d56f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_pred = {}\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    try:\n",
    "        new_team_err, new_opp_err, new_total_err, actual, opp_actual, pred, opp_pred = get_errors_mssa(team_name)\n",
    "        \n",
    "        team_errs.append(new_team_err)\n",
    "        opp_errs.append(new_opp_err)\n",
    "        total_errs.append(new_total_err)\n",
    "\n",
    "        team_to_pred[team_name] = (actual, opp_actual, pred, opp_pred)\n",
    "    except:\n",
    "        print(\"Failed here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bad35-bd1e-4184-966f-7bde0a3ff986",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c0dd6-a553-490b-a4ab-0dea7ea58e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f6694-16a3-46e0-9761-697df9a1f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b7323-5643-49b8-930e-ba30336014fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf282db-9dde-4991-9e1e-e39e5a1d8125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9af73-d30d-4e80-b164-532f00dec4e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    try:\n",
    "        new_team_err, new_opp_err, new_total_err = get_errors_mssa(team_name, use_one_matrix=True)\n",
    "        \n",
    "        team_errs.append(new_team_err)\n",
    "        opp_errs.append(new_opp_err)\n",
    "        total_errs.append(new_total_err)\n",
    "    except:\n",
    "        print(\"Failed here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72aba1-8688-43ba-a54f-be181d71bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63edf2ea-6034-4c8d-97be-8c7ef565cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97aa3c1-f55e-476d-bd6e-9217827b418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e9129-905a-4019-9952-ffcd52b55754",
   "metadata": {},
   "source": [
    "## Full Game Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea9c3e0-4771-49af-a8c9-1d9ae52aee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_game_errors_mssa(team_name, T=100, interval_seconds=24, to_fill_zeros=False, use_one_matrix=False):\n",
    "    pred_series, true_series = predict_last_game_mssa(\n",
    "        data_dir, team_name, T=T, \n",
    "        interval_seconds=interval_seconds, \n",
    "        to_fill_zeros=to_fill_zeros,\n",
    "        use_one_matrix=use_one_matrix,\n",
    "        predict_full_game=True\n",
    "    )\n",
    "    half_T = T//2\n",
    "    \n",
    "    pred_series = [np.cumsum(pred_series[0]), np.cumsum(pred_series[1])]\n",
    "    true_series = [np.cumsum(true_series[0]), np.cumsum(true_series[1])]\n",
    "\n",
    "    team_score_err = np.abs(pred_series[0][-1] - true_series[0][-1])\n",
    "    opp_score_err = np.abs(pred_series[1][-1] - true_series[1][-1])\n",
    "    total_err = np.abs((pred_series[0][-1] + pred_series[1][-1]) - (true_series[0][-1] + true_series[1][-1]))\n",
    "\n",
    "    actual = true_series[0][-1]\n",
    "    opp_actual = true_series[1][-1]\n",
    "    team_pred = pred_series[0][-1]\n",
    "    opp_pred = pred_series[1][-1]\n",
    "    \n",
    "    return team_score_err, opp_score_err, total_err, actual, opp_actual, team_pred, opp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab9866-b70a-4262-a27c-5f92b9335295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_pred = {}\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    try:\n",
    "        new_team_err, new_opp_err, new_total_err, actual, opp_actual, pred, opp_pred = get_full_game_errors_mssa(team_name)\n",
    "        \n",
    "        team_errs.append(new_team_err)\n",
    "        opp_errs.append(new_opp_err)\n",
    "        total_errs.append(new_total_err)\n",
    "\n",
    "        team_to_pred[team_name] = (actual, opp_actual, pred, opp_pred)\n",
    "    except ValueError:\n",
    "        print(\"Failed here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ea671-9447-4b85-934b-93c36873e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614628c3-55f9-4676-ad9f-033b2ed9bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fbef8b-c8b4-4f84-9ed2-da904ec434bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ab5a0-03a1-4aa8-943b-43f8d6b8ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2a1b6-cdac-46ef-a154-099135eb23a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f76c271-28e9-4f69-862f-cc691bc47d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_over_under_return(game_odds, team_to_pred, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec3627-85bc-4335-af8b-b3ab9828a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_spread_return(game_odds, team_to_pred, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f73f986-7a32-4a11-8152-738040f05fda",
   "metadata": {},
   "source": [
    "## Poisson Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda38b98-e3c2-4f65-9f81-1f5d9cb1f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_last_game_poisson(team_name, T=100, interval_seconds=24, predict_full_game=False):\n",
    "    half_T = T//2\n",
    "    \n",
    "    team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, team_name, interval_seconds=interval_seconds)\n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "\n",
    "    lambda_team = np.sum(team_scores[:-1].flatten())/(len(team_scores[:-1].flatten()) * 24)\n",
    "    lambda_opp = np.sum(opponent_scores[:-1].flatten())/(len(opponent_scores[:-1].flatten()) * 24)\n",
    "\n",
    "    time_remaining = 2400 if predict_full_game else 1200\n",
    "\n",
    "    simulated_team_scores = np.random.poisson(lam=lambda_team * time_remaining, size=1000)\n",
    "    simulated_opp_scores = np.random.poisson(lam=lambda_opp * time_remaining, size=1000)\n",
    "\n",
    "    if not predict_full_game:\n",
    "        first_half_team_score = np.sum(team_scores[-1][:half_T])\n",
    "        first_half_opp_score = np.sum(opponent_scores[-1][:half_T])\n",
    "    \n",
    "        final_team_scores = simulated_team_scores + first_half_team_score\n",
    "        final_opp_scores = simulated_opp_scores + first_half_opp_score\n",
    "    else:\n",
    "        final_team_scores = simulated_team_scores\n",
    "        final_opp_scores = simulated_opp_scores\n",
    "    \n",
    "    actual_team = np.sum(team_scores[-1])\n",
    "    actual_opp = np.sum(opponent_scores[-1])\n",
    "\n",
    "    return np.mean(final_team_scores), np.mean(final_opp_scores), actual_team, actual_opp\n",
    "\n",
    "def get_errors_poisson(team_name, T=100, interval_seconds=24, predict_full_game=False):\n",
    "    pred_team, pred_opp, actual_team, actual_opp = predict_last_game_poisson(\n",
    "        team_name, T=T, interval_seconds=interval_seconds,\n",
    "        predict_full_game=predict_full_game\n",
    "    )\n",
    "\n",
    "    team_err = np.abs(pred_team - actual_team)\n",
    "    team_opp = np.abs(pred_opp - actual_opp)\n",
    "    team_total = np.abs((pred_team + pred_opp) - (actual_team + actual_opp))\n",
    "    return team_err, team_opp, team_total, actual_team, actual_opp, pred_team, pred_opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee111b1-94b1-4a83-9825-9106005a07c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_pred = {}\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    new_team_err, new_opp_err, new_total_err, actual_team, actual_opp, pred_team, pred_opp = get_errors_poisson(team_name)\n",
    "\n",
    "    team_errs.append(new_team_err)\n",
    "    opp_errs.append(new_opp_err)\n",
    "    total_errs.append(new_total_err)\n",
    "    team_to_pred[team_name] = (actual_team, actual_opp, pred_team, pred_opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e67eb2-0445-4cc9-8931-8d9d6976795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119bcfb-ddc8-4b4f-86c5-b03e540b30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0bacc2-122a-4c7b-b549-721da4531593",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26846e4-07ce-4cce-99fb-eac40deff4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "840abb65-efe7-4501-92df-e306cb48761f",
   "metadata": {},
   "source": [
    "## Poisson Full Game Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4f02e-c206-428c-bce6-caec2db3067f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_pred = {}\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    new_team_err, new_opp_err, new_total_err, actual_team, actual_opp, pred_team, pred_opp = get_errors_poisson(\n",
    "        team_name, predict_full_game=True\n",
    "    )\n",
    "\n",
    "    team_errs.append(new_team_err)\n",
    "    opp_errs.append(new_opp_err)\n",
    "    total_errs.append(new_total_err)\n",
    "    team_to_pred[team_name] = (actual_team, actual_opp, pred_team, pred_opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020de0b-9dfe-46d9-9635-11f224d5b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d99a3-7b1e-4f38-ba76-236748d98e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c77d5-7f2d-4d66-a395-57e6f177d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057b53f-a2a8-4aab-bb2d-3af745b348c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1a5de-c5df-4532-af63-c08ee261f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_over_under_return(game_odds, team_to_pred, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a5056-255e-42f0-91a9-c7e2a5435396",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_spread_return(game_odds, team_to_pred, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfc390-fdd0-4341-a90e-29902c7049b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7789e-627d-4730-9aef-b08d4df303f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3778c975-246d-4b79-850e-adb88c0b6d7b",
   "metadata": {},
   "source": [
    "## Episodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87d56f-89f5-4317-a015-24f7ca6b6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def svd_denoising(page_matrix):\n",
    "    U, s, VT = svd(page_matrix, full_matrices=False)\n",
    "    r = get_important_rank(s)\n",
    "    S_r = np.diag(s[:r])\n",
    "    X_denoised = (U[:, :r] @ S_r @ VT[:r, :])\n",
    "    return X_denoised\n",
    "\n",
    "def get_synthetic_weights(X0, X1):\n",
    "    n_controls = X0.shape[1]\n",
    "    \n",
    "    def loss_fn(w):\n",
    "        return np.linalg.norm(X1 - X0 @ w)**2\n",
    "    \n",
    "    cons = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1) for _ in range(n_controls)]\n",
    "    \n",
    "    result = minimize(loss_fn, x0=np.ones(n_controls)/n_controls,\n",
    "                      bounds=bounds, constraints=cons, jac=False)\n",
    "    return result.x\n",
    "\n",
    "def predict_second_half(game_matrix, final_game_first_half, plot_results=False, print_weights=False):\n",
    "    \"\"\"\n",
    "    Use synthetic control to predict the second half of a final game based on:\n",
    "    1. Matrix of complete historical games (both halves)\n",
    "    2. First half data from the final game\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    game_matrix : numpy array or pandas DataFrame\n",
    "        Matrix of historical games where:\n",
    "        - Each row is a different game\n",
    "        - First half of columns are first-half scores\n",
    "        - Second half of columns are second-half scores\n",
    "    final_game_first_half : numpy array or list\n",
    "        First-half data for the final game we want to predict\n",
    "    plot_results : bool\n",
    "        Whether to plot the results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict containing:\n",
    "        predicted_second_half: predicted scores for second half of final game\n",
    "        weights: weights assigned to control games\n",
    "        synthetic_first_half: for validation (how well the synthetic control matched the first half)\n",
    "        first_half_rmse: root mean squared error of first half prediction\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays if needed\n",
    "    if isinstance(game_matrix, pd.DataFrame):\n",
    "        game_names = game_matrix.index\n",
    "        feature_names = game_matrix.columns\n",
    "        game_matrix = game_matrix.values\n",
    "    else:\n",
    "        game_names = [f\"Game {i+1}\" for i in range(game_matrix.shape[0])]\n",
    "        feature_names = [f\"Feature {i+1}\" for i in range(game_matrix.shape[1])]\n",
    "    \n",
    "    # Determine number of features in each half\n",
    "    n_features = game_matrix.shape[1]\n",
    "    n_half_features = n_features // 2\n",
    "    \n",
    "    # Extract first and second halves from historical games\n",
    "    historical_first_halves = game_matrix[:, :n_half_features]\n",
    "    # historical_first_halves = svd_denoising(historical_first_halves)\n",
    "    historical_second_halves = game_matrix[:, n_half_features:]\n",
    "    # historical_second_halves = svd_denoising(historical_second_halves)\n",
    "\n",
    "    beta = get_synthetic_weights(historical_first_halves.T, final_game_first_half)\n",
    "    \n",
    "    # Calculate synthetic first half for validation\n",
    "    synthetic_first_half = historical_first_halves.T @ beta\n",
    "    \n",
    "    # Calculate predicted second half\n",
    "    predicted_second_half = historical_second_halves.T @ beta\n",
    "    predicted_second_half = predicted_second_half.reshape(-1)\n",
    "    \n",
    "    # Calculate first half RMSE for accuracy assessment\n",
    "    first_half_rmse = np.sqrt(np.mean((final_game_first_half - synthetic_first_half)**2))\n",
    "    \n",
    "    # Plot if requested\n",
    "    if plot_results:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Plot actual first half vs. synthetic first half\n",
    "        x_first = range(n_half_features)\n",
    "        x_second = range(n_half_features, n_half_features * 2)\n",
    "        \n",
    "        ax.plot(x_first, final_game_first_half, 'o-', color='black', label='Actual First Half')\n",
    "        ax.plot(x_first, synthetic_first_half, 's--', color='blue', label='Synthetic First Half')\n",
    "        \n",
    "        # Plot predicted second half\n",
    "        ax.plot(x_second, predicted_second_half, 'd--', color='red', label='Predicted Second Half')\n",
    "        \n",
    "        # Add vertical line separating halves\n",
    "        ax.axvline(x=n_half_features - 0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Add labels\n",
    "        ax.set_title('Synthetic Control Prediction for Second Half')\n",
    "        ax.set_xlabel('Feature')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if print_weights:\n",
    "        # Display top contributing games\n",
    "        print(\"Top contributing games to the synthetic control:\")\n",
    "        sorted_weights = sorted(zip(game_names, weights), key=lambda x: x[1], reverse=True)\n",
    "        for game, weight in sorted_weights:\n",
    "            if weight > 0.01:  # Only show games with weights > 1%\n",
    "                print(f\"{game}: {weight:.4f}\")\n",
    "        \n",
    "        print(f\"\\nFirst half RMSE: {first_half_rmse:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'predicted_second_half': predicted_second_half,\n",
    "        'weights': beta,\n",
    "        'synthetic_first_half': synthetic_first_half,\n",
    "        'first_half_rmse': first_half_rmse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5e613-3f05-403d-a79a-11258c524ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_last_game_episodic(data_dir, team_name, T=100, interval_seconds=24):\n",
    "    # Generate example data: 20 historical games, 5 stats per half (10 total)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, team_name, interval_seconds=interval_seconds)\n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    N = len(team_scores)\n",
    "    half_T = T//2\n",
    "    \n",
    "    train_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(N-1)])[:, :, :T]\n",
    "    test_game = np.array([team_scores[-1], opponent_scores[-1]])\n",
    "    test_half = test_game[:, :half_T]\n",
    "    \n",
    "    # Run prediction\n",
    "    team_results = predict_second_half(train_games[:, 0, :], test_half[0])\n",
    "    opp_results = predict_second_half(train_games[:, 1, :], test_half[1])\n",
    "    \n",
    "    predicted_team_series = np.hstack([test_game[0, :half_T], team_results['predicted_second_half']])\n",
    "    predicted_opp_series = np.hstack([test_game[1, :half_T], opp_results['predicted_second_half']])\n",
    "    return [predicted_team_series, predicted_opp_series], test_game\n",
    "\n",
    "predicted_series, test_game = predict_last_game_episodic(data_dir, 'UConn')\n",
    "plot_forecast(predicted_series, test_game)\n",
    "plot_forecast(predicted_series, test_game, diff_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15715dec-5710-49a0-8608-3cbcd73efaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors_episodic(team_name, T=100, interval_seconds=24, to_fill_zeros=False):\n",
    "    pred_series, true_series = predict_last_game_episodic(\n",
    "        data_dir, team_name, T=T, \n",
    "        interval_seconds=interval_seconds\n",
    "    )\n",
    "\n",
    "    pred_series = [reconstruct_score(true_series[0], pred_series[0], half_T), reconstruct_score(true_series[1], pred_series[1], half_T)]\n",
    "    true_series = [np.cumsum(true_series[0]), np.cumsum(true_series[1])]\n",
    "    \n",
    "    team_score_err = np.abs(pred_series[0][-1] - true_series[0][-1])\n",
    "    opp_score_err = np.abs(pred_series[1][-1] - true_series[1][-1])\n",
    "    total_err = np.abs((pred_series[0][-1] + pred_series[1][-1]) - (true_series[0][-1] + true_series[1][-1]))\n",
    "    return team_score_err, opp_score_err, total_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3a2a3-312f-45b0-b38a-57675b2f440b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    new_team_err, new_opp_err, new_total_err = get_errors_episodic(team_name)\n",
    "    \n",
    "    team_errs.append(new_team_err)\n",
    "    opp_errs.append(new_opp_err)\n",
    "    total_errs.append(new_total_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84425c-c66b-4aac-b480-2b9a639a0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae72c16-dc7a-4779-b2de-33f345d4cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abba55-3786-4ea1-b289-e2c775baf244",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca91a0-dedb-4322-93ec-4ceb9c93e4f3",
   "metadata": {},
   "source": [
    "## Metaheuristic Clustering (Trapezoid of Excellence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e3584-4544-4850-bc23-d2fdabc687c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_pages = [\n",
    "    \"stats-off-scoring-margin\",\n",
    "    \"stats-off-points-per-game\",\n",
    "    \"stats-off-fg-percent\",\n",
    "    \"stats-off-2p-percent\",\n",
    "    \"stats-off-3p-percent\",\n",
    "    \"stats-off-ft-percent\",\n",
    "    \"stats-off-assists-per-game\",\n",
    "    \"stats-off-to-per-game\",\n",
    "    \"stats-off-assist-to-tov\",\n",
    "    \"stats-def-points-per-game\",\n",
    "    \"stats-def-fg-percent\",\n",
    "    \"stats-def-2p-percent\",\n",
    "    \"stats-def-3p-percent\",\n",
    "    \"stats-def-steals\",\n",
    "    \"stats-def-blocks\",\n",
    "    \"stats-def-fouls\",\n",
    "    \"stats-adv-offensive-rating\",\n",
    "    \"stats-adv-defensive-rating\",\n",
    "    \"stats-adv-net-rating\",\n",
    "    \"stats-adv-pace\",\n",
    "    \"stats-adv-fta-rate\",\n",
    "    \"stats-adv-3pa-rate\",\n",
    "    \"stats-adv-efg-percent\",\n",
    "    \"stats-adv-true-shooting-percent\",\n",
    "    \"stats-adv-orb-percent\",\n",
    "    \"stats-adv-drb-percent\",\n",
    "    \"stats-adv-total-rebound-percent\",\n",
    "    \"stats-adv-assist-percent\",\n",
    "    \"stats-adv-steal-percent\",\n",
    "    \"stats-adv-block-percent\",\n",
    "]\n",
    "\n",
    "stats = [\n",
    "    'scoring_margin',\n",
    "    'points_per_game',\n",
    "    'fg_percentage',\n",
    "    '2-point-percentage',\n",
    "    '3-point-percentage',\n",
    "    'free-throw-percentage',\n",
    "    'assists_per_game',\n",
    "    'tos_per_game',\n",
    "    'assist_to_to',\n",
    "    'points_allowed_per_game',\n",
    "    'fg_percentage_allowed',\n",
    "    '2-point-percentage-allowed',\n",
    "    '3-point-percentage-allowed',\n",
    "    'steals_per_game',\n",
    "    'blocks_per_game',\n",
    "    'fouls_per_game',\n",
    "    'offensive_rating',\n",
    "    'defensive_rating',\n",
    "    'net_rating',\n",
    "    'pace',\n",
    "    'free_throw_attempt_rate',\n",
    "    'three_point_attempt_rate',\n",
    "    'effective_field_goal_percentage',\n",
    "    'true_shooting_percentage',\n",
    "    'offensive_rebound_percentage',\n",
    "    'total_rebound_percentage',\n",
    "    'assist_percentage',\n",
    "    'steal_percentage',\n",
    "    'block_percentage'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7f1e6-d6c6-4f08-bbf4-14ec86101682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_stat(stat_page):\n",
    "    # Step 1: Send a request to the website\n",
    "    url = f\"https://www.warrennolan.com/basketball/2024/{stat_page}\"  # Replace with your target website\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Step 2: Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Step 3: Locate and extract the statistics\n",
    "    # This depends on the structure of the website\n",
    "    # Example for a table with class 'stats-table'\n",
    "    stats_table = soup.find('table', class_='stats-table')\n",
    "    \n",
    "    # Step 4: Extract data from the table\n",
    "    data = []\n",
    "    if stats_table:\n",
    "        rows = stats_table.find_all('tr')\n",
    "        for row in rows[1:]:  # Skip header row\n",
    "            columns = row.find_all('td')\n",
    "            if columns:\n",
    "                stat = {\n",
    "                    'rank': columns[0].text.strip(),\n",
    "                    'name': columns[1].text.strip(),\n",
    "                    'value': columns[2].text.strip() if len(columns) > 2 else ''\n",
    "                }\n",
    "                data.append(stat)\n",
    "    \n",
    "    # Step 5: Convert to DataFrame and save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_all_stats():\n",
    "    all_dfs = []\n",
    "    for stat_page in stat_pages:\n",
    "        all_dfs.append(scrape_stat(stat_page))\n",
    "\n",
    "    return all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3504e2-7581-4dbd-a83f-cfd58a37b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stat_dfs = get_all_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e205b-ecce-44c5-9035-b4aa82556a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store team stats\n",
    "team_stats = {}\n",
    "\n",
    "# Process each DataFrame\n",
    "for df, stat_name in zip(all_stat_dfs, stats):\n",
    "    for _, row in df.iterrows():\n",
    "        team = row['name']\n",
    "        value = row['value']\n",
    "        \n",
    "        # Initialize team entry if it doesn't exist\n",
    "        if team not in team_stats:\n",
    "            team_stats[team] = {}\n",
    "        \n",
    "        # Add this stat to the team's entry\n",
    "        team_stats[team][stat_name] = value\n",
    "\n",
    "# Now team_stats contains a mapping of each team to all its stats\n",
    "# Example: \n",
    "# team_stats = {\n",
    "#     'Team A': {'goals': 42, 'assists': 30, 'saves': 120},\n",
    "#     'Team B': {'goals': 38, 'assists': 25, 'saves': 110},\n",
    "#     # ...\n",
    "# }\n",
    "\n",
    "# If you want to convert back to a single DataFrame for analysis:\n",
    "combined_df = pd.DataFrame.from_dict(team_stats, orient='index')\n",
    "combined_df.reset_index(inplace=True)\n",
    "combined_df.rename(columns={'index': 'team_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8979a5-c4dc-49f6-9c71-8824eb30de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe720969-aa59-4e0d-b44f-2906f7cc14b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(combined_df['team_name'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95112f1-e5c9-4608-81b8-97916790c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOURNAMENT_TEAMS = [\n",
    "    # EAST \n",
    "    \"UConn\", \"Iowa_State\", \"Illinois\", \"Auburn\", \"San_Diego_State\", \"BYU\", \"Washington_St\", \"FAU\", \"Northwestern\", \"Drake\", \"Duquesne\",\n",
    "    \"UAB\", \"Yale\", \"Morehead_State\", \"South_Dakota_St\", \"Stetson\",\n",
    "    # WEST\n",
    "    \"Arizona\", \"Baylor\", \"Alabama\", \"Saint_Mary's\", \"Clemson\", \"Dayton\", \"Miss_St\", \"Michigan_State\", \"Nevada\", \"New_Mexico\",\n",
    "    \"Grand_Canyon\", \"Charleston\", \"Colgate\", \"Long_Beach_State\", \"Howard\", \"Wagner\",\n",
    "    #SOUTH\n",
    "    \"Houston\", \"Marquette\", \"Kentucky\", \"Duke\", \"Wisconsin\", \"Texas_Tech\", \"Florida\", \"Nebraska\", \"Texas_A&M\", \"Boise_State\",\n",
    "    \"Colorado\", \"NC_State\", \"JMU\", \"Vermont\", \"Oakland\", \"W_Kentucky\", \"Longwood\",\n",
    "    #MIDWEST\n",
    "    \"Purdue\", \"Tennessee\", \"Creighton\", \"Kansas\", \"Gonzaga\", \"South_Carolina\", \"Texas\", \"Utah_State\", \"TCU\", \"UVA\", \"Colorado_State\",\n",
    "    \"Oregon\", \"McNeese\", \"Samford\", \"Akron\", \"St_Peter's\", \"Montana_State\", \"Grambling\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5769a63-12bc-4628-9130-81b8be26dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCAA_HOOP_TO_WARRENNOLAN = {\n",
    "    'UConn': 'Connecticut', 'Iowa_State': 'Iowa State', 'Saint Mary\\'s': 'Saint Mary\\'s College', 'Miss State': 'Mississippi State',\n",
    "    'NC State': 'North Carolina State', 'JMU': 'James Madison', 'W Kentucky': 'Western Kentucky', 'UVA': 'Virginia', \n",
    "    'St Peter\\'s': 'Saint Peter\\'s', 'Grambling': 'Grambling State', 'St. John\\'s': 'Saint John\\'s'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac1608-1875-4f4f-99fe-14fc772f2621",
   "metadata": {},
   "outputs": [],
   "source": [
    "for team in TOURNAMENT_TEAMS:\n",
    "    transformed_team_name = team.replace('_', ' ')\n",
    "    if transformed_team_name.endswith('St'):\n",
    "        transformed_team_name += \"ate\"\n",
    "\n",
    "    transformed_team_name = NCAA_HOOP_TO_WARRENNOLAN.get(transformed_team_name, transformed_team_name)\n",
    "    team_row = combined_df[combined_df['team_name'] == transformed_team_name]\n",
    "    team_row = team_row.to_numpy()\n",
    "    \n",
    "    if len(team_row) == 0:\n",
    "        print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34dc1a2-d67a-4002-86c8-d7a08f691d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trapezoid_coord(team):\n",
    "    transformed_team_name = team.replace('_', ' ')\n",
    "    if transformed_team_name.endswith('St'):\n",
    "        transformed_team_name += \"ate\"\n",
    "\n",
    "    transformed_team_name = NCAA_HOOP_TO_WARRENNOLAN.get(transformed_team_name, transformed_team_name)\n",
    "    team_row = combined_df[combined_df['team_name'] == transformed_team_name].to_numpy()[0]\n",
    "    return (float(team_row[4]), float(team_row[3]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dfe021-88c4-41e2-9d01-46e747a8300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coords = []\n",
    "for team in TOURNAMENT_TEAMS:\n",
    "    all_coords.append(get_trapezoid_coord(team))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c19fde-baa6-495d-bd31-d16b0f87a300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paces, net_ratings = [point[0] for point in all_coords], [point[1] for point in all_coords]\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(paces, net_ratings, s=100, alpha=0.7)\n",
    "\n",
    "for i, label in enumerate(TOURNAMENT_TEAMS[:5]):\n",
    "    x, y = all_coords[i]\n",
    "    plt.annotate(label,\n",
    "                 (x, y),\n",
    "                 xytext=(5, 5),  # Small offset so text doesn't overlap with point\n",
    "                 textcoords='offset points',\n",
    "                 fontsize=10)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Pace')\n",
    "plt.ylabel('Net Rating')\n",
    "plt.title('Trapezoid of Excellence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331b5a6-0979-4a53-93a5-606cf6546713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_clean_name(team):\n",
    "    transformed_team_name = team.replace('_', ' ')\n",
    "    if transformed_team_name.endswith('St'):\n",
    "        transformed_team_name += \"ate\"\n",
    "\n",
    "    transformed_team_name = NCAA_HOOP_TO_WARRENNOLAN.get(transformed_team_name, transformed_team_name)\n",
    "    return transformed_team_name\n",
    "\n",
    "def get_matchups(data_directory, team_name):\n",
    "    \"\"\"\n",
    "    Extract scores for all games of a specific team from ncaahoopR_data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_directory : str\n",
    "        Path to the ncaahoopR_data directory\n",
    "    team_name : str\n",
    "        The team name to extract scores for\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing game information and scores\n",
    "    \"\"\"\n",
    "    # Load the team's schedule to get game IDs\n",
    "    schedule_path = os.path.join(data_directory, \"schedules\", f\"{team_name}_schedule.csv\")\n",
    "    if not os.path.exists(schedule_path):\n",
    "        raise ValueError(f\"Schedule for {team_name} not found at {schedule_path}\")\n",
    "    \n",
    "    schedule = pd.read_csv(schedule_path)\n",
    "    matchups = []\n",
    "    for _, row in schedule.iterrows():\n",
    "        matchups.append([row['game_id'], get_clean_name(team_name), row['opponent']])\n",
    "    \n",
    "    return matchups\n",
    "\n",
    "def get_all_matchups():\n",
    "    all_matchups = []\n",
    "    for team in TOURNAMENT_TEAMS:\n",
    "        all_matchups += get_matchups(data_dir, team)\n",
    "    return all_matchups\n",
    "\n",
    "def get_team_embedding(team, heuristic_indices):\n",
    "    team_row = combined_df[combined_df['team_name'] == team].to_numpy()\n",
    "    if not len(team_row):\n",
    "        raise ValueError(f\"Can't find team: {team}\")\n",
    "    team_row = team_row[0]\n",
    "        \n",
    "    embedding = []\n",
    "    for index in heuristic_indices:\n",
    "        val = team_row[index]\n",
    "        val = val.replace('%', '')\n",
    "        embedding.append(float(val))\n",
    "\n",
    "    embedding = np.array(embedding)\n",
    "\n",
    "    norm = np.linalg.norm(embedding)\n",
    "    if norm > 0:\n",
    "        embedding = embedding / norm\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def make_matchup_embeds(matchups, heuristic_indices=[4, 3]):\n",
    "    embedded_matchups = []\n",
    "    for game_id, team_1, team_2 in matchups:\n",
    "        try:\n",
    "            team_1_embed = get_team_embedding(team_1, heuristic_indices)\n",
    "            team_2_embed = get_team_embedding(team_2, heuristic_indices)\n",
    "            \n",
    "            forward_embed = np.hstack((team_1_embed, team_2_embed))\n",
    "            reverse_embed = np.hstack((team_2_embed, team_1_embed))\n",
    "            \n",
    "            embedded_matchups.append([game_id, team_1, team_2, forward_embed])\n",
    "            embedded_matchups.append([game_id, team_2, team_1, reverse_embed])\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return embedded_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdb07f-c935-4f20-9aca-878c1a7bfc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matchups = get_all_matchups()\n",
    "embedded_matchups = make_matchup_embeds(all_matchups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206275b-ca46-44df-967b-77b988a8d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedded_matchups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00377cbc-3f04-4893-b622-6e04a7f85c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_games(game_data, query_embedding, top_k=5):\n",
    "    \"\"\"\n",
    "    Find most similar games based on embedding similarity\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    game_data : list\n",
    "        List of lists where each inner list contains [game_id, team1, team2, embedding]\n",
    "    query_embedding : list or np.array\n",
    "        The query embedding vector to compare against\n",
    "    top_k : int\n",
    "        Number of most similar games to return\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of game_ids sorted by similarity (highest first)\n",
    "    \"\"\"\n",
    "    # Convert query embedding to numpy array for efficient computation\n",
    "    query_embedding = np.array(query_embedding)\n",
    "    \n",
    "    # Calculate cosine similarity between query embedding and each game embedding\n",
    "    similarities = []\n",
    "    for game_id, team1, team2, embedding in game_data:\n",
    "        # Convert game embedding to numpy array\n",
    "        game_embedding = np.array(embedding)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity(query_embedding, game_embedding)\n",
    "        similarities.append(((game_id, team1, team2), similarity))\n",
    "    \n",
    "    # Sort by similarity (highest first)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top K game IDs\n",
    "    return [game_id for game_id, _ in similarities[:top_k]]\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    vec1, vec2 : np.array\n",
    "        Vectors to compare\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Cosine similarity (between -1 and 1)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5858da2-bd58-48e0-98f4-7a68b6ef8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_games(embedded_matchups, [63, 4, 67, 10], top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80ca64-1e4a-49e0-81ca-0e9713239b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_matchup(data_directory, team_name, interval_seconds=24):\n",
    "    # Load the team's schedule to get game IDs\n",
    "    schedule_path = os.path.join(data_directory, \"schedules\", f\"{team_name}_schedule.csv\")\n",
    "    if not os.path.exists(schedule_path):\n",
    "        raise ValueError(f\"Schedule for {team_name} not found at {schedule_path}\")\n",
    "    \n",
    "    schedule = pd.read_csv(schedule_path)\n",
    "    \n",
    "    # Create a results dataframe\n",
    "    results = []\n",
    "\n",
    "    game = schedule.iloc[-1]\n",
    "    \n",
    "    game_id = game['game_id']\n",
    "    \n",
    "    # Look for the play-by-play file\n",
    "    pbp_path = os.path.join(data_directory, \"pbp_logs\", \"**\", f\"{game_id}.csv\")\n",
    "    pbp_files = glob.glob(pbp_path, recursive=True)\n",
    "    \n",
    "    if not pbp_files:\n",
    "        raise ValueError(f\"PBP data for game {game_id} not found\")\n",
    "        \n",
    "    # Load the play-by-play data\n",
    "    pbp_data = pd.read_csv(pbp_files[0])\n",
    "    \n",
    "    # Extract the score\n",
    "    sampled_scores = sample_score_at_intervals(pbp_data, interval_seconds=interval_seconds)\n",
    "\n",
    "    return sampled_scores\n",
    "\n",
    "def get_similar_game_scores(data_dir, team_name, embedded_matchups, heuristic_indices, interval_seconds=15, top_k=5):\n",
    "\n",
    "    last_matchup = get_last_matchup(data_dir, team_name)\n",
    "\n",
    "    test_score, test_opp_score, opp_team = attribute_scores(last_matchup, team_name)\n",
    "\n",
    "    query_embed = np.hstack([\n",
    "        get_team_embedding(get_clean_name(team_name), heuristic_indices),\n",
    "        get_team_embedding(get_clean_name(opp_team), heuristic_indices)\n",
    "    ])\n",
    "    \n",
    "    similar_games = find_similar_games(embedded_matchups, query_embed, top_k=top_k)\n",
    "    \n",
    "    # Create a results dataframe\n",
    "    all_target_scores, all_other_scores, other_teams = [], [], []\n",
    "    \n",
    "    # Process each game in the schedule\n",
    "    for game in similar_games:\n",
    "        game_id = game[0]\n",
    "        team1 = game[1]\n",
    "        \n",
    "        # Look for the play-by-play file\n",
    "        pbp_path = os.path.join(data_dir, \"pbp_logs\", \"**\", f\"{game_id}.csv\")\n",
    "        pbp_files = glob.glob(pbp_path, recursive=True)\n",
    "        \n",
    "        if not pbp_files:\n",
    "            print(f\"PBP data for game {game_id} not found\")\n",
    "            continue\n",
    "            \n",
    "        # Load the play-by-play data\n",
    "        pbp_data = pd.read_csv(pbp_files[0])\n",
    "        \n",
    "        # Extract the score\n",
    "        sampled_scores = sample_score_at_intervals(pbp_data, interval_seconds=interval_seconds)\n",
    "        \n",
    "        new_targ, new_other, new_team = attribute_scores(sampled_scores, team1)\n",
    "\n",
    "        all_target_scores.append(new_targ)\n",
    "        all_other_scores.append(new_other)\n",
    "        other_teams.append(new_team)\n",
    "    \n",
    "    return all_target_scores, all_other_scores, test_score, test_opp_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b8302-aa30-48f9-990e-a18c7313a68f",
   "metadata": {},
   "source": [
    "## Embedding mSSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32234b1-a2f3-481a-a017-b32dcab95eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_last_game_mssa_embed(\n",
    "    data_dir, \n",
    "    team_name, \n",
    "    embedded_matchups,\n",
    "    interval_seconds=60, \n",
    "    T=40, \n",
    "    to_fill_zeros=False, \n",
    "    predict_full_game=False,\n",
    "    heuristic_indices=[4, 3], \n",
    "    top_k=5\n",
    "):\n",
    "    half_T = T//2\n",
    "    \n",
    "    team_scores, opponent_scores, test_score, test_opp_score = get_similar_game_scores(\n",
    "        data_dir, team_name, embedded_matchups, heuristic_indices, interval_seconds=interval_seconds, top_k=top_k\n",
    "    )\n",
    "    \n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    test_score = np.diff(test_score)\n",
    "    test_opp_score = np.diff(test_opp_score)\n",
    "    N = len(team_scores)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    train_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(N)])[:, :, :T]\n",
    "    test_game = np.array([test_score, test_opp_score])\n",
    "    test_half = test_game[:, :half_T]\n",
    "\n",
    "    if predict_full_game:\n",
    "        to_append = np.ones_like(test_game) * np.mean(train_games)\n",
    "        to_append = to_append.reshape((1, 2, T))\n",
    "    else:\n",
    "        test_half = test_game[:, :half_T]\n",
    "        if to_fill_zeros:\n",
    "            fill_in = np.zeros(test_half.shape)\n",
    "        else:\n",
    "            fill_in = np.ones(test_half.shape) * np.mean(train_games)\n",
    "        \n",
    "        to_append = np.hstack((test_half, fill_in)).reshape(1, 2, T)\n",
    "    \n",
    "    all_games = np.vstack((train_games, to_append))\n",
    "\n",
    "    target_wide, opp_wide = make_wide_matrices(all_games, T)\n",
    "\n",
    "    target_series = finish_mSSA(target_wide, opp_wide, all_games, T, half_T)\n",
    "\n",
    "    return target_series, test_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0fd6a-26c1-404d-82f2-3a1099e810db",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_indices = [4, 3]\n",
    "all_matchups = get_all_matchups()\n",
    "embedded_matchups = make_matchup_embeds(all_matchups, heuristic_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a098b6e-9ebf-4c2e-89b4-d296441812bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_series, test_game = predict_last_game_mssa_embed(\n",
    "    data_dir, 'Auburn', embedded_matchups, interval_seconds=24, T=100, \n",
    "    to_fill_zeros=False, heuristic_indices=heuristic_indices,\n",
    "    top_k=200, predict_full_game=True\n",
    ")\n",
    "plot_forecast(pred_series, true_series, half_T=half_T)\n",
    "plot_forecast(pred_series, true_series, half_T=half_T, diff_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12350a5-3fa8-4ef3-ab92-cb2f7fe7d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "def get_errors_mssa_embed(\n",
    "    team_name, \n",
    "    embedded_matchups,\n",
    "    T=100, \n",
    "    interval_seconds=24, \n",
    "    to_fill_zeros=False,\n",
    "    heuristic_indices=[4, 3], \n",
    "    top_k=1, predict_full_game=False\n",
    "):\n",
    "    pred_series, true_series = predict_last_game_mssa_embed(\n",
    "        data_dir, team_name, embedded_matchups, T=T, \n",
    "        interval_seconds=interval_seconds, \n",
    "        to_fill_zeros=to_fill_zeros,\n",
    "        heuristic_indices=heuristic_indices,\n",
    "        top_k=top_k, predict_full_game=predict_full_game\n",
    "    )\n",
    "    half_T = T//2\n",
    "\n",
    "    if predict_full_game:\n",
    "        pred_series = [np.cumsum(pred_series[0]), np.cumsum(pred_series[1])]\n",
    "    else:\n",
    "        pred_series = [reconstruct_score(true_series[0], pred_series[0], half_T), reconstruct_score(true_series[1], pred_series[1], half_T)]\n",
    "    true_series = [np.cumsum(true_series[0]), np.cumsum(true_series[1])]\n",
    "\n",
    "    team_score_err = np.abs(pred_series[0][-1] - true_series[0][-1])\n",
    "    opp_score_err = np.abs(pred_series[1][-1] - true_series[1][-1])\n",
    "    total_err = np.abs((pred_series[0][-1] + pred_series[1][-1]) - (true_series[0][-1] + true_series[1][-1]))\n",
    "\n",
    "    actual = true_series[0][-1]\n",
    "    opp_actual = true_series[1][-1]\n",
    "    team_pred = pred_series[0][-1]\n",
    "    opp_pred = pred_series[1][-1]\n",
    "    \n",
    "    return team_score_err, opp_score_err, total_err, actual, opp_actual, team_pred, opp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de341d9-73b3-4ab6-8b25-5170f3d5900f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heuristic_indices = [4, 3]\n",
    "all_matchups = get_all_matchups()\n",
    "embedded_matchups = make_matchup_embeds(all_matchups, heuristic_indices)\n",
    "\n",
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_pred = {}\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    try:\n",
    "        new_team_err, new_opp_err, new_total_err, actual, opp_actual, team_pred, opp_pred = get_errors_mssa_embed(\n",
    "            team_name, embedded_matchups, interval_seconds=24, T=100, \n",
    "            to_fill_zeros=False, heuristic_indices=heuristic_indices,\n",
    "            top_k=200\n",
    "        )\n",
    "    \n",
    "        team_errs.append(new_team_err)\n",
    "        opp_errs.append(new_opp_err)\n",
    "        total_errs.append(new_total_err)\n",
    "\n",
    "        team_to_pred[team_name] = (actual, opp_actual, team_pred, opp_pred)\n",
    "    except ValueError:\n",
    "        print(f\"Failed on team: {team_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76991c1d-8571-4fc6-b57c-fcc47df9c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e76153-ff6c-4c6d-8926-5d845d0f098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e5ce1-e1c9-439c-8e0a-9175433a77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0d483-f302-456f-8b59-80ee56a62ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de11626c-5805-4d64-85a1-f6fe4870c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f3b2f-c8fc-452c-bac1-a7d8b272cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754591a1-c03a-4ffd-96b0-d0383963eaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac5a83-dffb-44b2-972b-86d5bb47285a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heuristic_indices = [4, 3]\n",
    "all_matchups = get_all_matchups()\n",
    "embedded_matchups = make_matchup_embeds(all_matchups, heuristic_indices)\n",
    "\n",
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_pred = {}\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    try:\n",
    "        new_team_err, new_opp_err, new_total_err, actual, opp_actual, team_pred, opp_pred = get_errors_mssa_embed(\n",
    "            team_name, embedded_matchups, interval_seconds=24, T=100, \n",
    "            to_fill_zeros=False, heuristic_indices=heuristic_indices,\n",
    "            top_k=200, predict_full_game=True\n",
    "        )\n",
    "    \n",
    "        team_errs.append(new_team_err)\n",
    "        opp_errs.append(new_opp_err)\n",
    "        total_errs.append(new_total_err)\n",
    "\n",
    "        team_to_pred[team_name] = (actual, opp_actual, team_pred, opp_pred)\n",
    "    except ValueError:\n",
    "        print(f\"Failed on team: {team_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c511f6-63df-4585-8002-51cc78da5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699cfd5-1552-4805-b663-4a3e6c1493af",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229056df-41c3-4a83-bc54-e513e30e9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bbfe5-e955-45b9-84d2-0b1bf0d1c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7f33b-b0be-410a-9681-d718c41bb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_over_under_return(game_odds, team_to_pred, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183cc70-8a94-4530-afc0-7fbe172fa512",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_spread_return(game_odds, team_to_pred, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f282fcf-5395-4489-a9a7-387b81eb91c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44185d-7e4a-4303-93e7-0523817f70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_last_game_episodic_embed(\n",
    "    team_name, \n",
    "    embedded_matchups,\n",
    "    T=100, \n",
    "    interval_seconds=24, \n",
    "    heuristic_indices=[4, 3], \n",
    "    top_k=1\n",
    "):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    team_scores, opponent_scores, test_score, test_opp_score = get_similar_game_scores(\n",
    "        data_dir, team_name, embedded_matchups, heuristic_indices, interval_seconds=interval_seconds, top_k=top_k\n",
    "    )\n",
    "    \n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    test_score = np.diff(test_score)\n",
    "    test_opp_score = np.diff(test_opp_score)\n",
    "    N = len(team_scores)\n",
    "    half_T = T//2\n",
    "    \n",
    "    train_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(N)])[:, :, :T]\n",
    "    test_game = np.array([test_score, test_opp_score])\n",
    "    test_half = test_game[:, :half_T]\n",
    "    \n",
    "    # Run prediction\n",
    "    team_results = predict_second_half(train_games[:, 0, :], test_half[0])\n",
    "    opp_results = predict_second_half(train_games[:, 1, :], test_half[1])\n",
    "    \n",
    "    predicted_team_series = np.hstack([test_game[0, :half_T], team_results['predicted_second_half']])\n",
    "    predicted_opp_series = np.hstack([test_game[1, :half_T], opp_results['predicted_second_half']])\n",
    "    return [predicted_team_series, predicted_opp_series], test_game\n",
    "\n",
    "predicted_series, test_game = predict_last_game_episodic(data_dir, 'San_Diego_State')\n",
    "plot_forecast(predicted_series, test_game)\n",
    "plot_forecast(predicted_series, test_game, diff_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fe754-e988-41ad-819d-c2e7c4628ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "def get_errors_episodic_embed(\n",
    "    team_name, \n",
    "    embedded_matchups,\n",
    "    T=100, \n",
    "    interval_seconds=24, \n",
    "    heuristic_indices=[4, 3], \n",
    "    top_k=1\n",
    "):\n",
    "    pred_series, true_series = predict_last_game_episodic_embed(\n",
    "        team_name, embedded_matchups, T=T, \n",
    "        interval_seconds=interval_seconds, \n",
    "        heuristic_indices=heuristic_indices,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    half_T = T//2\n",
    "    \n",
    "    pred_series = [reconstruct_score(true_series[0], pred_series[0], half_T), reconstruct_score(true_series[1], pred_series[1], half_T)]\n",
    "    true_series = [np.cumsum(true_series[0]), np.cumsum(true_series[1])]\n",
    "\n",
    "    team_score_err = np.abs(pred_series[0][-1] - true_series[0][-1])\n",
    "    opp_score_err = np.abs(pred_series[1][-1] - true_series[1][-1])\n",
    "    total_err = np.abs((pred_series[0][-1] + pred_series[1][-1]) - (true_series[0][-1] + true_series[1][-1]))\n",
    "    return team_score_err, opp_score_err, total_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e08c86-48bf-424d-809e-bcdf010846c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_indices = [4, 3]\n",
    "all_matchups = get_all_matchups()\n",
    "embedded_matchups = make_matchup_embeds(all_matchups, heuristic_indices)\n",
    "\n",
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    new_team_err, new_opp_err, new_total_err = get_errors_episodic_embed(\n",
    "        team_name, embedded_matchups, interval_seconds=24, T=100, \n",
    "        heuristic_indices=heuristic_indices,\n",
    "        top_k=20\n",
    "    )\n",
    "\n",
    "    team_errs.append(new_team_err)\n",
    "    opp_errs.append(new_opp_err)\n",
    "    total_errs.append(new_total_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d78f1-eae2-4a78-aa88-756d9e5d8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43fbba-afa9-4a11-9771-045f913b8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a765ec-4c6f-4e09-8a70-fb14e70892d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d019cdf-9a29-4fdc-9c39-e1f9458974a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_forecasts(team_name, T, interval_seconds):\n",
    "    half_T = T//2\n",
    "\n",
    "    lr_pred_series, lr_true_series = predict_last_game_lr(data_dir, team_name)\n",
    "\n",
    "    mssa_pred_series, mssa_true_series = predict_last_game_mssa(\n",
    "        data_dir, team_name, T=T, \n",
    "        interval_seconds=interval_seconds, \n",
    "        to_fill_zeros=False\n",
    "    )\n",
    "\n",
    "    pmf_team_preds, pmf_odd_preds = [], []\n",
    "    pmf_pred_series, _, _ = predict_last_game_pmf_reconstruct(team_name, seed = 5)\n",
    "    pmf_team_preds.append(pmf_pred_series[0])\n",
    "    pmf_odd_preds.append(pmf_pred_series[1])\n",
    "\n",
    "    # pmf_pred_series = [np.median(pmf_team_preds, axis=0), np.median(pmf_odd_preds, axis=0)]\n",
    "\n",
    "\n",
    "    all_pred_series = [lr_pred_series, mssa_pred_series, pmf_pred_series]\n",
    "    alg_labels = ['ARX', 'mSSA', 'PMF']\n",
    "    \n",
    "    plot_comp_forecast(all_pred_series, alg_labels, lr_true_series, half_T, school_name=team_name)\n",
    "    plot_comp_forecast(all_pred_series, alg_labels, lr_true_series, half_T, school_name=team_name, diff_score=False)\n",
    "\n",
    "def plot_comp_forecast(all_pred_series, alg_labels, true_series, half_T=50, diff_score=True, school_name=''):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    labels = [f'{school_name} Home Score', 'Away Score']\n",
    "    for i in range(2):\n",
    "        plt.subplot(2, 1, i+1)\n",
    "        if diff_score:\n",
    "            plt.plot(true_series[i], label='True', color='black')\n",
    "            for pred_series, alg_label in zip(all_pred_series, alg_labels):\n",
    "                plt.plot(pred_series[i], '--', label=alg_label)\n",
    "        else:\n",
    "            plt.plot(np.cumsum(true_series[i]), label='True', color='black')\n",
    "            for pred_series, alg_label in zip(all_pred_series, alg_labels):\n",
    "                plt.plot(reconstruct_score(true_series[i], pred_series[i], half_T), '--', label=alg_label)\n",
    "        plt.axvline(half_T, color='gray', linestyle=':', label='Forecast Start')\n",
    "        plt.title(labels[i])\n",
    "        plt.legend(loc=2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{'Differenced ' if diff_score else ''} Forecast Comparison.png')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba74bdc-e300-4c9e-9bc4-2e5255dde2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_forecasts('UConn', 100, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32afeb1-e1e0-48c4-bc7e-e017973eaa21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e73ad-19ff-4dc7-af01-76dfb6d3e55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d1f65-1072-49b6-aa0d-7dfa2956dbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d6432-fa03-40a1-9458-0312484c8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.special import gammaln\n",
    "\n",
    "class PMF:\n",
    "    def __init__(self, n_factors=10, reg_lambda=0.1, learning_rate=0.001, max_iter=100):\n",
    "        \"\"\"\n",
    "        Initialize the Probabilistic Matrix Factorization model\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_factors : int\n",
    "            Number of latent factors\n",
    "        reg_lambda : float\n",
    "            Regularization parameter\n",
    "        learning_rate : float\n",
    "            Learning rate for gradient descent\n",
    "        max_iter : int\n",
    "            Maximum number of iterations\n",
    "        \"\"\"\n",
    "        self.n_factors = n_factors\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        # These will be initialized based on data dimensions\n",
    "        self.U = None  # Game latent factors\n",
    "        self.V = None  # Time point latent factors\n",
    "        \n",
    "    def _init_parameters(self, n_games, n_timepoints):\n",
    "        \"\"\"Initialize model parameters with small random values\"\"\"\n",
    "        self.U = np.random.normal(scale=0.1, size=(n_games, self.n_factors))\n",
    "        self.V = np.random.normal(scale=0.1, size=(self.n_factors, n_timepoints))\n",
    "        \n",
    "    def _objective(self, params, *args):\n",
    "        \"\"\"\n",
    "        Compute the objective function: sum of squared errors + regularization\n",
    "        \n",
    "        Used for L-BFGS optimization\n",
    "        \"\"\"\n",
    "        R, I, n_games, n_timepoints, _ = args\n",
    "        \n",
    "        # Reshape params back into U and V\n",
    "        U = params[:n_games * self.n_factors].reshape(n_games, self.n_factors)\n",
    "        V = params[n_games * self.n_factors:].reshape(self.n_factors, n_timepoints)\n",
    "        \n",
    "        # Compute predictions\n",
    "        pred = np.dot(U, V)\n",
    "        \n",
    "        # Compute error only on observed entries\n",
    "        err = I * (R - pred)\n",
    "        \n",
    "        # Sum of squared errors\n",
    "        sse = np.sum(err ** 2)\n",
    "        \n",
    "        # Add regularization\n",
    "        reg = self.reg_lambda * (np.sum(U ** 2) + np.sum(V ** 2))\n",
    "        \n",
    "        # Total objective\n",
    "        obj = sse + reg\n",
    "        \n",
    "        return obj\n",
    "\n",
    "    def _nb_objective(self, params, *args):\n",
    "        R, I, n_games, n_timepoints, r = args\n",
    "        \n",
    "        U = params[:n_games * self.n_factors].reshape(n_games, self.n_factors)\n",
    "        V = params[n_games * self.n_factors:].reshape(self.n_factors, n_timepoints)\n",
    "        \n",
    "        log_mu = np.dot(U, V)  # no exp yet\n",
    "        mu = np.exp(log_mu)  # ensure positivity\n",
    "        \n",
    "        # Compute NB log-likelihood only for observed entries\n",
    "        eps = 1e-8  # numerical stability\n",
    "        log_prob = (\n",
    "            gammaln(R + r) - gammaln(R + 1) - gammaln(r)\n",
    "            + r * np.log(r / (r + mu + eps))\n",
    "            + R * np.log(mu / (r + mu + eps))\n",
    "        )\n",
    "        \n",
    "        # Negative log-likelihood\n",
    "        neg_log_lik = -np.sum(I * log_prob)\n",
    "        \n",
    "        # Regularization\n",
    "        reg = self.reg_lambda * (np.sum(U**2) + np.sum(V**2))\n",
    "        \n",
    "        return neg_log_lik + reg\n",
    "    \n",
    "    def _gradient(self, params, *args):\n",
    "        \"\"\"\n",
    "        Compute the gradient of the objective function\n",
    "        \n",
    "        Used for L-BFGS optimization\n",
    "        \"\"\"\n",
    "        R, I, n_games, n_timepoints, _ = args\n",
    "        \n",
    "        # Reshape params back into U and V\n",
    "        U = params[:n_games * self.n_factors].reshape(n_games, self.n_factors)\n",
    "        V = params[n_games * self.n_factors:].reshape(self.n_factors, n_timepoints)\n",
    "        \n",
    "        # Compute predictions\n",
    "        pred = np.dot(U, V)\n",
    "        \n",
    "        # Compute error only on observed entries\n",
    "        err = I * (pred - R)\n",
    "        \n",
    "        # Gradient for U\n",
    "        grad_U = np.dot(err, V.T) + self.reg_lambda * U\n",
    "        \n",
    "        # Gradient for V\n",
    "        grad_V = np.dot(U.T, err) + self.reg_lambda * V\n",
    "        \n",
    "        # Concatenate gradients\n",
    "        grad = np.concatenate([grad_U.flatten(), grad_V.flatten()])\n",
    "        \n",
    "        return grad\n",
    "\n",
    "    def _nb_gradient(self, params, *args):\n",
    "        R, I, n_games, n_timepoints, r = args\n",
    "    \n",
    "        U = params[:n_games * self.n_factors].reshape(n_games, self.n_factors)\n",
    "        V = params[n_games * self.n_factors:].reshape(self.n_factors, n_timepoints)\n",
    "    \n",
    "        Z = np.dot(U, V)             # shape (n_games, n_timepoints)\n",
    "        mu = np.exp(Z)               # ensure positivity\n",
    "    \n",
    "        # Precompute gradient multiplier\n",
    "        numer = R * (mu + r) - (R + r) * mu\n",
    "        denom = mu + r\n",
    "        coef = I * (numer / denom)   # shape (n_games, n_timepoints)\n",
    "    \n",
    "        # Gradients via chain rule\n",
    "        grad_U = np.dot(coef, V.T) + self.reg_lambda * U\n",
    "        grad_V = np.dot(U.T, coef) + self.reg_lambda * V\n",
    "    \n",
    "        grad = np.concatenate([grad_U.flatten(), grad_V.flatten()])\n",
    "        return -grad  # n\n",
    "    \n",
    "    # def fit(self, R, mask=None):\n",
    "    #     \"\"\"\n",
    "    #     Fit the PMF model to the data matrix R\n",
    "        \n",
    "    #     Parameters:\n",
    "    #     -----------\n",
    "    #     R : numpy.ndarray\n",
    "    #         Matrix of observations (games x timepoints)\n",
    "    #     mask : numpy.ndarray, optional\n",
    "    #         Binary matrix indicating observed entries (1 = observed, 0 = missing)\n",
    "    #     \"\"\"\n",
    "    #     n_games, n_timepoints = R.shape\n",
    "        \n",
    "    #     # Create mask if not provided (assume all entries are observed)\n",
    "    #     if mask is None:\n",
    "    #         mask = np.ones_like(R)\n",
    "            \n",
    "    #     # Initialize parameters\n",
    "    #     self._init_parameters(n_games, n_timepoints)\n",
    "        \n",
    "    #     # Flatten parameters for L-BFGS\n",
    "    #     initial_params = np.concatenate([self.U.flatten(), self.V.flatten()])\n",
    "        \n",
    "    #     # Optimize using L-BFGS\n",
    "    #     args = (R, mask, n_games, n_timepoints)\n",
    "    #     result = fmin_l_bfgs_b(self._objective, initial_params, \n",
    "    #                           fprime=self._gradient, args=args, \n",
    "    #                           maxiter=self.max_iter)\n",
    "        \n",
    "    #     optimal_params = result[0]\n",
    "        \n",
    "    #     # Reshape optimal parameters back into U and V\n",
    "    #     self.U = optimal_params[:n_games * self.n_factors].reshape(n_games, self.n_factors)\n",
    "    #     self.V = optimal_params[n_games * self.n_factors:].reshape(self.n_factors, n_timepoints)\n",
    "        \n",
    "    #     return self\n",
    "\n",
    "    def fit(self, R, mask=None, r=10.0):\n",
    "        n_games, n_timepoints = R.shape\n",
    "        if mask is None:\n",
    "            mask = np.ones_like(R)\n",
    "        \n",
    "        self._init_parameters(n_games, n_timepoints)\n",
    "        initial_params = np.concatenate([self.U.flatten(), self.V.flatten()])\n",
    "        \n",
    "        args = (R, mask, n_games, n_timepoints, r)\n",
    "        self.initial_train_set = R\n",
    "        result = fmin_l_bfgs_b(self._nb_objective, initial_params, fprime=self._nb_gradient,\n",
    "                               args=args, maxiter=self.max_iter)\n",
    "        \n",
    "        optimal_params = result[0]\n",
    "        self.U = optimal_params[:n_games * self.n_factors].reshape(n_games, self.n_factors)\n",
    "        self.V = optimal_params[n_games * self.n_factors:].reshape(self.n_factors, n_timepoints)\n",
    "        return self\n",
    "\n",
    "    def reconstruct_matrix(self):\n",
    "        \"\"\"\n",
    "        Reconstruct the original data matrix using the learned latent factors.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        reconstructed : numpy.ndarray\n",
    "            Reconstructed data matrix (n_games x n_timepoints)\n",
    "        \"\"\"\n",
    "        if self.U is None or self.V is None:\n",
    "            raise ValueError(\"Model has not been fit yet. Call fit() first.\")\n",
    "        \n",
    "        # Dot product of U and V gives the reconstructed matrix\n",
    "        reconstructed = np.dot(self.U, self.V)\n",
    "        \n",
    "        # For the negative binomial model, apply exp() to get back to original scale\n",
    "        # Note: Only apply this if you're using the negative binomial model\n",
    "        # reconstructed = np.exp(reconstructed)\n",
    "        \n",
    "        return reconstructed\n",
    "\n",
    "    def reconstruct_matrix_nb(self, T=100):\n",
    "        \"\"\"\n",
    "        Reconstruct the original data matrix using the learned latent factors\n",
    "        for the negative binomial model.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        reconstructed : numpy.ndarray\n",
    "            Reconstructed data matrix (n_games x n_timepoints)\n",
    "        \"\"\"\n",
    "        if self.U is None or self.V is None:\n",
    "            raise ValueError(\"Model has not been fit yet. Call fit() first.\")\n",
    "        \n",
    "        # For negative binomial model, we model log(mean)\n",
    "        log_mu = np.dot(self.U, self.V)\n",
    "\n",
    "        N = len(log_mu)\n",
    "        scalar = (N * T - (T//2))/(N * T)\n",
    "        \n",
    "        # # Convert back to count scale\n",
    "        reconstructed = np.exp(log_mu)\n",
    "        \n",
    "        return reconstructed * scalar\n",
    "\n",
    "    def generate_game_prediction(self, n_games, reference_games=None, variation=0.1, is_nb=True):\n",
    "        if self.U is None or self.V is None:\n",
    "            raise ValueError(\"Model has not been fit yet. Call fit() first.\")\n",
    "        \n",
    "        # Get dimensions\n",
    "        n_train, n_factors = self.U.shape\n",
    "        _, n_timepoints = self.V.shape\n",
    "        \n",
    "        # Select reference games\n",
    "        if reference_games is None:\n",
    "            # Use all training games as references\n",
    "            U_ref = self.U\n",
    "        else:\n",
    "            # Use only the specified reference games\n",
    "            U_ref = self.U[reference_games]\n",
    "        \n",
    "        n_ref = U_ref.shape[0]\n",
    "        \n",
    "        # Generate predictions using linear combinations of reference games\n",
    "        predictions = np.zeros((n_games, n_timepoints))\n",
    "        \n",
    "        for i in range(n_games):\n",
    "            # Sample weights from Dirichlet distribution\n",
    "            # Alpha=1 gives uniform weights, higher values give more uniform weights\n",
    "            alpha = 1.0\n",
    "            weights = np.random.dirichlet(alpha * np.ones(n_ref))\n",
    "            \n",
    "            # Create linear combination of reference game factors\n",
    "            U_combined = weights @ U_ref\n",
    "            \n",
    "            # Add noise proportional to the magnitude of the combined vector\n",
    "            noise_scale = variation * np.linalg.norm(U_combined)\n",
    "            noise = np.random.normal(0, noise_scale, n_factors)\n",
    "            \n",
    "            # Create new game factors\n",
    "            U_new = U_combined + noise\n",
    "            \n",
    "            # Generate prediction for this game\n",
    "            predictions[i] = U_new @ self.V\n",
    "        \n",
    "        # For negative binomial model, apply exp() to get back to count scale\n",
    "        if is_nb:\n",
    "            # Apply exp transformation to get to count scale\n",
    "            predictions = np.exp(predictions)\n",
    "            N = len(self.initial_train_set) if hasattr(self, 'initial_train_set') else n_train\n",
    "            T = 100  # Assuming T=100 as in the original code\n",
    "            scalar = (N * T - (T//2))/(N * T)\n",
    "            predictions = predictions * scalar\n",
    "        \n",
    "        return predictions\n",
    "        # if self.U is None or self.V is None:\n",
    "        #     raise ValueError(\"Model has not been fit yet. Call fit() first.\")\n",
    "    \n",
    "        # n_existing_games, n_factors = self.U.shape\n",
    "        # _, n_timepoints = self.V.shape\n",
    "        \n",
    "        # # Initialize array for new game factors\n",
    "        # U_new = np.zeros((n_games, n_factors))\n",
    "        \n",
    "        # # If reference_games is not provided, randomly select from existing games\n",
    "        # if reference_games is None:\n",
    "        #     reference_games = np.random.choice(n_existing_games, n_games)\n",
    "        # elif isinstance(reference_games, int):\n",
    "        #     # If a single index is provided, use it for all new games\n",
    "        #     reference_games = np.full(n_games, reference_games)\n",
    "        \n",
    "        # # Generate new game factors based on reference games\n",
    "        # for i in range(n_games):\n",
    "        #     ref_idx = reference_games[i] if i < len(reference_games) else reference_games[-1]\n",
    "            \n",
    "        #     # Take the latent factors of the reference game\n",
    "        #     ref_factors = self.U[ref_idx].copy()\n",
    "            \n",
    "        #     # Add controlled variation\n",
    "        #     if variation > 0:\n",
    "        #         # Scale the variation to the magnitude of each factor\n",
    "        #         factor_scales = np.abs(ref_factors) * variation\n",
    "        #         # Ensure minimum variation\n",
    "        #         factor_scales = np.maximum(factor_scales, 0.01 * variation)\n",
    "        #         # Add random variation\n",
    "        #         noise = np.random.normal(0, factor_scales)\n",
    "        #         ref_factors += noise\n",
    "            \n",
    "        #     U_new[i] = ref_factors\n",
    "        \n",
    "        # # Generate predictions\n",
    "        # predictions = np.dot(U_new, self.V)\n",
    "        \n",
    "        # # For negative binomial model, apply exp() to get back to count scale\n",
    "        # if is_nb:\n",
    "        #     predictions = np.exp(predictions - 0.25)\n",
    "            \n",
    "        #     # # Apply the scaling factor as in reconstruct_matrix_nb\n",
    "        #     # N = len(predictions)\n",
    "        #     # T = 100  # Assuming T=100 as in the original code\n",
    "        #     # scalar = (N * T - (T//2))/(N * T)\n",
    "        #     # predictions = predictions * scalar\n",
    "\n",
    "        #     # predictions -= (np.mean(predictions) - np.mean(self.initial_train_set))\n",
    "        \n",
    "        # return predictions\n",
    "    \n",
    "    def predict_second_half(self, first_half_data, train_games=None, is_nb=True, predict_full_game=False):\n",
    "        \"\"\"\n",
    "        Predict second half scores based on first half data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        first_half_data : numpy.ndarray\n",
    "            First half data for a game (or multiple games)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        second_half_pred : numpy.ndarray\n",
    "            Predicted second half scores\n",
    "        \"\"\"\n",
    "        \n",
    "        if first_half_data is None:\n",
    "            reconstructed = self.reconstruct_matrix_nb() if is_nb else self.reconstruct_matrix()\n",
    "            if predict_full_game:\n",
    "                return reconstructed[-1, :]\n",
    "            return reconstructed[-1, 50:]\n",
    "            \n",
    "        if len(first_half_data.shape) == 1:\n",
    "            # Single game case\n",
    "            first_half_data = first_half_data.reshape(1, -1)\n",
    "            \n",
    "        n_games, first_half_len = first_half_data.shape\n",
    "        second_half_len = self.V.shape[1] - first_half_len\n",
    "        \n",
    "        if second_half_len <= 0:\n",
    "            raise ValueError(\"Model doesn't contain information about second half timepoints\")\n",
    "        \n",
    "        # Infer latent factors for the new games based on first half data\n",
    "        # This is a simplified approach - in practice, you might want to use\n",
    "        # gradient descent to find optimal game factors\n",
    "        U_new = np.zeros((n_games, self.n_factors))\n",
    "        V_first_half = self.V[:, :first_half_len]\n",
    "        \n",
    "        for i in range(n_games):\n",
    "            # Solving for U_new: min ||first_half_data - U_new * V_first_half||^2 + reg * ||U_new||^2\n",
    "            A = V_first_half @ V_first_half.T + self.reg_lambda * np.eye(self.n_factors)\n",
    "            b = first_half_data[i] @ V_first_half.T\n",
    "            U_new[i] = np.linalg.solve(A, b)\n",
    "        \n",
    "        # Predict second half\n",
    "        V_second_half = self.V[:, first_half_len:]\n",
    "        second_half_pred = U_new @ V_second_half\n",
    "        \n",
    "        return second_half_pred if n_games > 1 else second_half_pred[0]\n",
    "\n",
    "# Example usage\n",
    "\n",
    "def create_synthetic_data(n_games=100, n_timepoints_per_half=50, n_factors=5):\n",
    "    \"\"\"Create synthetic game data for demonstration\"\"\"\n",
    "    # True latent factors\n",
    "    U_true = np.random.normal(size=(n_games, n_factors))\n",
    "    V_true = np.random.normal(size=(n_factors, n_timepoints_per_half * 2))\n",
    "    \n",
    "    # Generate true scores\n",
    "    true_scores = np.dot(U_true, V_true)\n",
    "    \n",
    "    # Add noise\n",
    "    noisy_scores = true_scores + np.random.normal(scale=0.1, size=true_scores.shape)\n",
    "    \n",
    "    return noisy_scores\n",
    "\n",
    "def evaluate_model(train_games, val_games, test_games, half_idx, n_factors=5, reg_lambda=0.1, max_iter=100, r=10.0):\n",
    "    \"\"\"Train model and evaluate predictions\"\"\"\n",
    "    # Split into first and second half\n",
    "    train_first_half = train_games[:, :half_idx]\n",
    "    train_second_half = train_games[:, half_idx:]\n",
    "    \n",
    "    test_first_half = test_games[:, :half_idx]\n",
    "    test_second_half = test_games[:, half_idx:]\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = PMF(n_factors=n_factors, reg_lambda=reg_lambda, max_iter=max_iter)\n",
    "    model.fit(train_games, r=r)\n",
    "\n",
    "    val_pred_second_half = model.predict_second_half(val_games[:, :half_index])\n",
    "    \n",
    "    # Predict second half for test games\n",
    "    pred_second_half = model.predict_second_half(test_first_half)\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    val_mse = np.mean((val_pred_second_half - val_games[:, half_idx:]) ** 2)\n",
    "    mse = np.mean((pred_second_half - test_second_half) ** 2)\n",
    "    \n",
    "    return model, val_mse, mse, pred_second_half, test_second_half\n",
    "\n",
    "def interleave_lists(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    \n",
    "    final = []\n",
    "    for i in range(len(a)):\n",
    "        final.append(a[i])\n",
    "        final.append(b[i])\n",
    "    return np.array(final)\n",
    "\n",
    "def predict_last_game_pmf_reconstruct(\n",
    "    team_name, T=100, interval_seconds=24, n_factors=30, \n",
    "    reg_lambda=0.1, max_iter=500, plot=False, seed=10, r=10.0,\n",
    "    predict_full_game=False\n",
    "):\n",
    "    half_T = T//2 \n",
    "    n_timepoints_per_half = T//2 \n",
    "    \n",
    "    # Create synthetic data\n",
    "    team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, team_name, interval_seconds=interval_seconds)\n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    team_scores = team_scores[:, :T]\n",
    "    opponent_scores = opponent_scores[:, :T]\n",
    "    N = len(team_scores)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    train_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(N-1)])[:, :, :T]\n",
    "    test_game = np.array([team_scores[-1], opponent_scores[-1]])\n",
    "\n",
    "    if predict_full_game:\n",
    "        to_append = np.ones_like(test_game) * np.mean(train_games)\n",
    "        to_append = to_append.reshape(1, 2, T)\n",
    "    else:\n",
    "        test_half = test_game[:, :half_T]\n",
    "        fill_in = np.ones_like(test_half) * np.mean(train_games)\n",
    "        to_append = np.hstack((test_half, fill_in)).reshape(1, 2, T)\n",
    "    \n",
    "    all_games = np.vstack((train_games, to_append))\n",
    "\n",
    "    # Train Model\n",
    "    team_model = PMF(n_factors=n_factors, reg_lambda=reg_lambda, max_iter=max_iter)\n",
    "    mask = np.ones_like(all_games[0, :])\n",
    "    if predict_full_game:\n",
    "        mask[-1, :] = 0\n",
    "    else:\n",
    "        mask[-1, half_T:] = 0\n",
    "        \n",
    "        team_model.fit(all_games[0, :], mask=mask, r=r)\n",
    "\n",
    "    # Use model to reconstruct a the new second half\n",
    "    if predict_full_game:\n",
    "        pred_second_halves = team_model.generate_game_prediction(1000)\n",
    "        pred_second_half = np.mean(pred_second_halves, axis=0)\n",
    "    else:\n",
    "        pred_second_half = team_model.predict_second_half(\n",
    "            None, \n",
    "            train_games=all_games[0, :-1],\n",
    "            predict_full_game=predict_full_game\n",
    "        )\n",
    "\n",
    "    if predict_full_game:\n",
    "        mse = np.mean((pred_second_half - test_game[0, :]) ** 2)\n",
    "    else:\n",
    "        mse = np.mean((pred_second_half - test_game[0, half_T:]) **2)\n",
    "\n",
    "    opp_model = PMF(n_factors=n_factors, reg_lambda=reg_lambda, max_iter=max_iter)\n",
    "\n",
    "    opp_model.fit(all_games[1, :], mask=mask, r=r)\n",
    "    \n",
    "    if predict_full_game:\n",
    "        opp_pred_second_halves = opp_model.generate_game_prediction(1000)\n",
    "        opp_pred_second_half = np.mean(opp_pred_second_halves, axis=0)\n",
    "    else:\n",
    "        opp_pred_second_half = opp_model.predict_second_half(\n",
    "            None, \n",
    "            train_games=all_games[1, :-1],\n",
    "            predict_full_game=predict_full_game\n",
    "        )\n",
    "\n",
    "    if predict_full_game:\n",
    "        opp_mse = np.mean((opp_pred_second_half - test_game[1, :]) ** 2)\n",
    "    else:\n",
    "        opp_mse = np.mean((opp_pred_second_half - test_game[1, half_T:]) ** 2)\n",
    "\n",
    "    if plot:\n",
    "        print(f\"MSE: {mse:.4f}, Opp MSE: {opp_mse:.4f}\")\n",
    "        \n",
    "        plot_predictions= np.array([predictions])\n",
    "        \n",
    "        # Plot results for a random test game\n",
    "        game_idx = 0\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        if predict_full_game:\n",
    "            plt.plot(range(T), test_game[game_idx], label=\"Actual\")\n",
    "            plt.plot(range(T), pred_second_half, 'r--', label=\"Predicted\")\n",
    "        else:\n",
    "            # Plot first half (actual)\n",
    "            first_half = test_game[game_idx, :n_timepoints_per_half]\n",
    "            plt.plot(range(n_timepoints_per_half), first_half, 'b-', label='First Half (Actual)')\n",
    "            \n",
    "            # Plot second half (actual)\n",
    "            second_half = test_game[game_idx, n_timepoints_per_half:]\n",
    "            plt.plot(range(n_timepoints_per_half, n_timepoints_per_half*2), \n",
    "                     second_half, 'g-', label='Second Half (Actual)')\n",
    "            \n",
    "            plt.plot(range(n_timepoints_per_half, n_timepoints_per_half*2), \n",
    "                     pred_second_half, 'r--', label='Second Half (Predicted)')\n",
    "        \n",
    "        plt.axvline(x=n_timepoints_per_half, color='k', linestyle='--')\n",
    "        plt.xlabel('Time point (24-second intervals)')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Game Score Prediction')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if predict_full_game:\n",
    "        full_pred_team = np.cumsum(pred_second_half)\n",
    "        full_pred_opp = np.cumsum(opp_pred_second_half)\n",
    "    else:\n",
    "        full_pred_team = np.hstack([test_game[0, :n_timepoints_per_half], pred_second_half])\n",
    "        full_pred_opp = np.hstack([test_game[1, :n_timepoints_per_half], opp_pred_second_half])\n",
    "\n",
    "    if predict_full_game:\n",
    "        return [full_pred_team, full_pred_opp], [np.cumsum(team_scores[-1]), np.cumsum(opponent_scores[-1])], 0.0, [pred_second_halves, opp_pred_second_halves]\n",
    "    return [full_pred_team, full_pred_opp], [np.cumsum(team_scores[-1]), np.cumsum(opponent_scores[-1])], 0.0\n",
    "\n",
    "def predict_last_game_pmf(\n",
    "    team_name='UConn', T=100, interval_seconds=24, n_factors=5, \n",
    "    reg_lambda=0.1, max_iter=500, r=10.0, plot=False, seed=10, \n",
    "    use_all_data=False\n",
    "):\n",
    "    n_timepoints_per_half = T//2 \n",
    "    \n",
    "    # Create synthetic data\n",
    "    team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, team_name, interval_seconds=interval_seconds)\n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    \n",
    "    team_scores = team_scores[:, :T]\n",
    "    opponent_scores = opponent_scores[:, :T]\n",
    "    n_games = len(team_scores)\n",
    "\n",
    "    N = len(team_scores)\n",
    "    \n",
    "    # Split into training and test sets\n",
    "    train_idx = int(0.8 * n_games)\n",
    "    train_games = team_scores[:n_games-4]\n",
    "    val_games = team_scores[n_games-4:n_games-1]\n",
    "    test_games = team_scores[n_games-1:]\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    model, val_mse, mse, predictions, actuals = evaluate_model(\n",
    "        train_games, val_games, test_games, n_timepoints_per_half,\n",
    "        n_factors=n_factors, reg_lambda=reg_lambda, max_iter=max_iter,\n",
    "        r=r\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        plot_predictions= np.array([predictions])\n",
    "        \n",
    "        # Plot results for a random test game\n",
    "        game_idx = np.random.randint(len(test_games))\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot first half (actual)\n",
    "        first_half = test_games[game_idx, :n_timepoints_per_half]\n",
    "        plt.plot(range(n_timepoints_per_half), first_half, 'b-', label='First Half (Actual)')\n",
    "        \n",
    "        # Plot second half (actual)\n",
    "        second_half = actuals[game_idx]\n",
    "        plt.plot(range(n_timepoints_per_half, n_timepoints_per_half*2), \n",
    "                 second_half, 'g-', label='Second Half (Actual)')\n",
    "        \n",
    "        # Plot second half (predicted)\n",
    "        pred_second_half = plot_predictions[game_idx]\n",
    "        plt.plot(range(n_timepoints_per_half, n_timepoints_per_half*2), \n",
    "                 pred_second_half, 'r--', label='Second Half (Predicted)')\n",
    "        \n",
    "        plt.axvline(x=n_timepoints_per_half, color='k', linestyle='--')\n",
    "        plt.xlabel('Time point (24-second intervals)')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Game Score Prediction')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    opp_train_games = opponent_scores[:len(team_scores)-4]\n",
    "    opp_val_games = opponent_scores[len(team_scores)-4:len(team_scores)-1]\n",
    "    opp_test_games = opponent_scores[len(team_scores)-1:]\n",
    "    opp_model, opp_val_mse, opp_mse, opp_predictions, opp_actuals = evaluate_model(\n",
    "        opp_train_games, opp_val_games, opp_test_games, n_timepoints_per_half,\n",
    "        n_factors=n_factors, reg_lambda=reg_lambda, max_iter=max_iter,\n",
    "        r=r\n",
    "    )\n",
    "\n",
    "    full_pred_team = np.hstack([test_games[0, :n_timepoints_per_half], predictions])\n",
    "    full_pred_opp = np.hstack([opp_test_games[0, :n_timepoints_per_half], opp_predictions])\n",
    "\n",
    "    return [full_pred_team, full_pred_opp], [team_scores[-1], opponent_scores[-1]], val_mse\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cef273-05dd-4394-b604-cd059e8225ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search(\n",
    "    train_games, \n",
    "    val_games, \n",
    "    r_values,\n",
    "    reg_lambda_values,\n",
    "    max_iter,\n",
    "    n_factors,\n",
    "    mask\n",
    "):\n",
    "    min_err, best_selection = float('inf'), (r_values[0], reg_lambda_values[0])\n",
    "    for r in r_values:\n",
    "        for reg_lambda in reg_lambda_values:\n",
    "            test_model = PMF(n_factors=n_factors, reg_lambda=reg_lambda, max_iter=max_iter)\n",
    "            test_model.fit(train_games, mask=mask, r=r)\n",
    "\n",
    "            pred_games = test_model.generate_game_prediction(1000)\n",
    "\n",
    "            predicted_scores = []\n",
    "            for game in pred_games:\n",
    "                tot = np.cumsum(game)\n",
    "                plt.plot(tot)\n",
    "                if tot[-1] > 150:\n",
    "                    continue\n",
    "                predicted_scores.append(tot[-1])\n",
    "\n",
    "            average_score = np.mean(predicted_scores)\n",
    "\n",
    "            val_errs = []\n",
    "            for game in val_games[0]:\n",
    "                final_score = np.cumsum(game)[-1]\n",
    "                val_errs.append(np.abs(average_score - final_score))\n",
    "\n",
    "            if np.mean(val_errs) < min_err:\n",
    "                best_selection = (r, reg_lambda)\n",
    "                \n",
    "    return best_selection\n",
    "\n",
    "def predict_full_game_pmf(\n",
    "    team_name, \n",
    "    T=100,\n",
    "    interval_seconds=24, \n",
    "    n_factors=30, \n",
    "    max_iter=500, \n",
    "    plot=False, \n",
    "    seed=10,\n",
    "    num_validation_games=3,\n",
    "    r_values = [5, 7.5, 10, 12.5, 15],\n",
    "    reg_lambda_values = [0.5, 0.6, 0.7, 0.8], \n",
    "):   \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Retrieve and process historical data\n",
    "    team_scores, opponent_scores, team_schedule = get_all_interval_scores(data_dir, team_name, interval_seconds=interval_seconds)\n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    team_scores = team_scores[:, :T]\n",
    "    opponent_scores = opponent_scores[:, :T]\n",
    "    N = len(team_scores)\n",
    "\n",
    "    train_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(N-(num_validation_games + 1))])[:, :, :T]\n",
    "    val_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(N-(num_validation_games + 1), N-1)])[:, :, :T]\n",
    "    test_game = np.array([team_scores[-1], opponent_scores[-1]])[:, :T]\n",
    "\n",
    "    # Fill matrix with fake game that just have average (For reconstruction tasks)\n",
    "    to_append = np.ones_like(test_game) * np.mean(train_games)\n",
    "    to_append = to_append.reshape(1, 2, T)\n",
    "    all_games = np.vstack((train_games, to_append))\n",
    "\n",
    "    # Hyperparameter Search with Validation Games\n",
    "    mask = np.ones_like(all_games[0, :])\n",
    "    mask[-1, :] = 0\n",
    "    \n",
    "    team_r, team_reg_lambda = hyperparameter_search(\n",
    "        all_games[0, :], val_games[0, :], r_values, \n",
    "        reg_lambda_values, max_iter, n_factors, mask\n",
    "    )\n",
    "                \n",
    "    # Train Model with best parameters on Validation Games\n",
    "    team_model = PMF(n_factors=n_factors, reg_lambda=team_reg_lambda, max_iter=max_iter)\n",
    "    team_model.fit(all_games[0, :], mask=mask, r=team_r)\n",
    "\n",
    "    # Use model to reconstruct a the new second half\n",
    "    pred_second_halves = team_model.generate_game_prediction(1000)\n",
    "    pred_second_half = np.mean(pred_second_halves, axis=0)\n",
    "\n",
    "    mse = np.mean((pred_second_half - test_game[0, :]) ** 2)\n",
    "\n",
    "    # Hyperparameter Search for Opponent Model\n",
    "    opp_r, opp_reg_lambda = hyperparameter_search(\n",
    "        all_games[1, :], val_games[1, :], r_values,\n",
    "        reg_lambda_values, max_iter, n_factors, mask\n",
    "    )\n",
    "\n",
    "    # Train Opponent Model with Validation Games\n",
    "    opp_model = PMF(n_factors=n_factors, reg_lambda=opp_reg_lambda, max_iter=max_iter)\n",
    "    opp_model.fit(all_games[1, :], mask=mask, r=opp_r)\n",
    "    opp_pred_second_halves = opp_model.generate_game_prediction(1000)\n",
    "    opp_pred_second_half = np.mean(opp_pred_second_halves, axis=0)\n",
    "\n",
    "    opp_mse = np.mean((opp_pred_second_half - test_game[1, :]) ** 2)\n",
    "\n",
    "    if plot:\n",
    "        print(f\"MSE: {mse:.4f}, Opp MSE: {opp_mse:.4f}\")\n",
    "        \n",
    "        # Plot results for a random test game\n",
    "        game_idx = 0\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.plot(range(T), test_game[game_idx], label=\"Actual\")\n",
    "        plt.plot(range(T), np.mean(pred_second_halves, axis=0), 'r--', label=\"Predicted\")\n",
    "        \n",
    "        plt.axvline(x=T//2, color='k', linestyle='--')\n",
    "        plt.xlabel('Time point (24-second intervals)')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Game Score Prediction')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    full_pred_team = np.cumsum(pred_second_half)\n",
    "    full_pred_opp = np.cumsum(opp_pred_second_half)\n",
    "    return ([full_pred_team, full_pred_opp], \n",
    "            [np.cumsum(team_scores[-1]), np.cumsum(opponent_scores[-1])], \n",
    "            0.0, \n",
    "            [pred_second_halves, opp_pred_second_halves])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfd89c-cc31-417c-921d-ccfc93198e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_means, res_stds, res_mean_errs, res_std_errs = [], [], [], []\n",
    "team_name='Marquette'\n",
    "predict_full_game=True\n",
    "r_values = [5, 7.5, 10, 12.5, 15]\n",
    "reg_lambda_values = [0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "for r in r_values:\n",
    "    means, stds, mean_errs, std_errs = [], [], [], []\n",
    "    for reg_lambda in reg_lambda_values:\n",
    "        predictions, actual = [], 0\n",
    "        if predict_full_game:\n",
    "            preds, reals, _,  all_pred_games= predict_last_game_pmf_reconstruct(\n",
    "                team_name=team_name, n_factors=30, plot=True, \n",
    "                seed=2, r=r, reg_lambda=reg_lambda, use_all_data=False,\n",
    "                predict_full_game=predict_full_game\n",
    "            )\n",
    "\n",
    "            for game in tqdm(all_pred_games[0]):\n",
    "                tot = np.cumsum(game)\n",
    "                plt.plot(tot)\n",
    "                if tot[-1] > 150:\n",
    "                    continue\n",
    "                predictions.append(tot[-1])\n",
    "        \n",
    "            plt.show()\n",
    "        \n",
    "            plt.hist(predictions)\n",
    "            plt.show()\n",
    "        else:\n",
    "            for i in range(10):\n",
    "                preds, reals, _ = predict_last_game_pmf_reconstruct(\n",
    "                    team_name=team_name, n_factors=30, plot=False, \n",
    "                    seed=i, r=r, reg_lambda=reg_lambda, use_all_data=False,\n",
    "                    predict_full_game=predict_full_game\n",
    "                )\n",
    "            \n",
    "                predictions.append(preds[0][-1])\n",
    "                    \n",
    "            plot_forecast(preds, reals, half_T=50)\n",
    "\n",
    "        actual = reals[0][-1]\n",
    "        \n",
    "        means.append(np.median(predictions))\n",
    "        stds.append(np.std(predictions))\n",
    "        mean_errs.append(np.mean([pred - actual for pred in predictions]))\n",
    "        std_errs.append(np.std([pred - actual for pred in predictions]))\n",
    "    res_means.append(means)\n",
    "    res_stds.append(stds)\n",
    "    res_mean_errs.append(mean_errs)\n",
    "    res_std_errs.append(std_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a974d30-49be-4fec-83df-68921b82cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "res_means = np.array(res_means)\n",
    "res_stds = np.array(res_stds)\n",
    "res_mean_errs = np.array(res_mean_errs)\n",
    "res_std_errs = np.array(res_std_errs)\n",
    "\n",
    "# Create the figure with a grid layout\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "gs = GridSpec(2, 1, figure=fig)\n",
    "\n",
    "plot_data = [\n",
    "    {\"title\": \"Predictions\", \"data\": res_means, \"stds\": res_stds, \"ax\": fig.add_subplot(gs[0, 0])},\n",
    "    {\"title\": \"Errors\", \"data\": res_mean_errs, \"stds\": res_std_errs, \"ax\": fig.add_subplot(gs[1, 0])},\n",
    "]\n",
    "\n",
    "\n",
    "# Colors for different r values\n",
    "colors = ['blue', 'green', 'red', 'purple', 'black', 'pink', 'orange']\n",
    "markers = ['o', 's', '^', 'd', '*']\n",
    "\n",
    "# Create each subplot\n",
    "for ind, plot in enumerate(plot_data):\n",
    "    ax = plot[\"ax\"]\n",
    "    data = plot[\"data\"]\n",
    "    std_data = plot[\"stds\"]\n",
    "    \n",
    "    # Plot each r value as a separate line\n",
    "    for i, r in enumerate(r_values):\n",
    "        ax.plot(reg_lambda_values, data[i], marker=markers[i % len(markers)], \n",
    "                linestyle='-', color=colors[i], label=f'r={r}')\n",
    "        ax.fill_between(reg_lambda_values, data[i] + std_data[i], data[i] - std_data[i],\n",
    "                       color=colors[i], alpha=0.3)\n",
    "    if ind == 0:\n",
    "        ax.axhline(y=actual, linestyle='--')\n",
    "    else:\n",
    "        ax.axhline(y=0, linestyle='--')\n",
    "    \n",
    "    # Set axis properties\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('reg_lambda')\n",
    "    ax.set_title(plot[\"title\"])\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f\"{team_name} Score Prediction Performance by Hyperparameters\", fontsize=16)\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1747a-7a3e-4fc5-b5cd-d73dbdeb9b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions), np.std(predictions), actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f675f0-938a-44e5-9755-f80d392d01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors_pmf(team_name, T=100, interval_seconds=24, n_factors=2):\n",
    "    predictions, opp_predictions, actual, opp_actual = [], [], 0, 0\n",
    "    for i in range(10):\n",
    "        preds, reals, _ = predict_last_game_pmf_reconstruct(team_name=team_name, n_factors=30, plot=False, seed=i, r=1000, reg_lambda=0.5)\n",
    "        predictions.append(preds[0][-1])\n",
    "        opp_predictions.append(preds[1][-1])\n",
    "        actual = reals[0][-1]\n",
    "        opp_actual = reals[1][-1]\n",
    "\n",
    "    team_pred, opp_pred = np.mean(predictions), np.mean(opp_predictions)\n",
    "    team_score_err = np.abs(team_pred - actual)\n",
    "    opp_score_err = np.abs(opp_pred - opp_actual)\n",
    "    total_err = np.abs((team_pred + opp_pred) - (actual + opp_actual))\n",
    "    return team_score_err, opp_score_err, total_err, actual, opp_actual, team_pred, opp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775777c-f2b2-45b6-8231-58b26e3fd235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_pred = {}\n",
    "problem_teams = set()\n",
    "for team_name in TOURNAMENT_TEAMS[:10]:\n",
    "    new_team_err, new_opp_err, new_total_err, actual, opp_actual, team_pred, opp_pred = get_errors_pmf(team_name, n_factors=30)\n",
    "    if new_team_err > 100:\n",
    "        problem_teams.add(team_name)\n",
    "    else:\n",
    "        team_errs.append(new_team_err)\n",
    "\n",
    "    if new_opp_err > 100:\n",
    "        problem_teams.add(team_name)\n",
    "    else:\n",
    "        opp_errs.append(new_opp_err)\n",
    "\n",
    "    if new_total_err > 100:\n",
    "        problem_teams.add(team_name)\n",
    "    else:\n",
    "        total_errs.append(new_total_err)\n",
    "\n",
    "    team_to_pred[team_name] = (actual, opp_actual, team_pred, opp_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de259b95-944c-4f52-bc49-91cbe44e79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac7541-a060-4def-8258-0a1fed4b6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a15f5f-73c2-4e21-a85d-a418dfae1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e08e17-07a6-4b14-9a81-0821ec7a1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856bc1fa-8e7b-40a8-b09e-2cae1105035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbfecd3-9870-4fc6-a6a1-8487c267eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d5941-7a1e-4b00-9099-ed07dec4a99f",
   "metadata": {},
   "source": [
    "## Full Game PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2be89e-6317-41b2-ba18-734807b1b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_game_errors_pmf(team_name, T=100, interval_seconds=24, n_factors=2):\n",
    "    predictions, opp_predictions, actual, opp_actual = [], [], 0, 0\n",
    "    preds, reals, _, all_pred_games = predict_full_game_pmf(\n",
    "        team_name=team_name, n_factors=30, plot=True, seed=i, \n",
    "        max_iter=100\n",
    "    )\n",
    "    for game in all_pred_games[0]:\n",
    "        tot = np.cumsum(game)\n",
    "        plt.plot(tot)\n",
    "        \n",
    "        if tot[-1] > 150:\n",
    "            continue\n",
    "        predictions.append(tot[-1])\n",
    "    plt.show()\n",
    "\n",
    "    for game in all_pred_games[1]:\n",
    "        tot = np.cumsum(game)\n",
    "\n",
    "        if tot[-1] > 150:\n",
    "            continue    \n",
    "        opp_predictions.append(tot[-1])\n",
    "\n",
    "    actual = reals[0][-1]\n",
    "    opp_actual = reals[1][-1]\n",
    "\n",
    "    team_pred, opp_pred = np.median(predictions), np.median(opp_predictions)\n",
    "    team_score_err = np.abs(team_pred - actual)\n",
    "    opp_score_err = np.abs(opp_pred - opp_actual)\n",
    "    total_err = np.abs((team_pred + opp_pred) - (actual + opp_actual))\n",
    "    return team_score_err, opp_score_err, total_err, actual, opp_actual, team_pred, opp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9c0ac-0be0-46f5-aa84-b09ed74f952a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs = [], [], []\n",
    "team_to_errs = {}\n",
    "team_to_preds = {}\n",
    "problem_teams = set()\n",
    "for team_name in tqdm(TOURNAMENT_TEAMS):\n",
    "    new_team_err, new_opp_err, new_total_err, actual, opp_actual, team_pred, opp_pred = get_full_game_errors_pmf(team_name, n_factors=30)\n",
    "    if new_team_err > 100:\n",
    "        problem_teams.add(team_name)\n",
    "    else:\n",
    "        team_errs.append(new_team_err)\n",
    "\n",
    "    if new_opp_err > 100:\n",
    "        problem_teams.add(team_name)\n",
    "    else:\n",
    "        opp_errs.append(new_opp_err)\n",
    "\n",
    "    if new_total_err > 100:\n",
    "        problem_teams.add(team_name)\n",
    "    else:\n",
    "        total_errs.append(new_total_err)\n",
    "\n",
    "    team_to_errs[team_name] = (new_team_err, new_opp_err, new_total_err)\n",
    "    team_to_preds[team_name] = (actual, opp_actual, team_pred, opp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b534d52-2178-4315-9ab4-aecfe61ec463",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(team_errs), np.nanstd(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93820a96-df39-46c4-a02c-f8fb8dbb4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(opp_errs), np.nanstd(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f57d89-939d-404d-974c-72bc8644deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(total_errs), np.nanstd(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080cb55-cf7a-49c2-898b-701811f88783",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8476b88-bd58-4fd1-a8c7-8728d3ba66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_to_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c413e-2623-4e10-b786-d30d0806907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_to_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102eb61d-aa78-4c94-9229-10d7f3592f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_over_under_return(game_odds, team_to_preds, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890a4f9-f4eb-4178-bcd8-b1e2d5e608ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_spread_return(game_odds, team_to_preds, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fb69e-e4b9-43c9-a60d-355d788228a5",
   "metadata": {},
   "source": [
    "## Embed NBPMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61046141-7d51-4409-a3d9-d452ababf8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_indices = [4, 3]\n",
    "all_matchups = get_all_matchups()\n",
    "embedded_matchups = make_matchup_embeds(all_matchups, heuristic_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabaa0e-2744-495a-9bf0-9c02f027fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_last_game_pmf_embed(team_name,\n",
    "    heuristic_indices=[4, 3], interval_seconds=24, T=100, top_k=50,\n",
    "    n_factors=5, reg_lambda=0.5, max_iter=100, plot=False, r=100, seed=1, \n",
    "    predict_full_game=False, use_all_data=False                           \n",
    "):\n",
    "    half_T = T//2\n",
    "    n_timepoints_per_half = T//2\n",
    "    \n",
    "    team_scores, opponent_scores, test_score, test_opp_score = get_similar_game_scores(\n",
    "        data_dir, team_name, embedded_matchups, heuristic_indices, interval_seconds=interval_seconds, top_k=top_k\n",
    "    )\n",
    "    \n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    test_score = np.diff(test_score)\n",
    "    test_opp_score = np.diff(test_opp_score)\n",
    "    \n",
    "    team_scores = team_scores[:, :T]\n",
    "    opponent_scores = opponent_scores[:, :T]\n",
    "    test_score = test_score[:T]\n",
    "    test_opp_score = test_opp_score[:T]\n",
    "    N = len(team_scores)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    train_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(5, N)])[:, :, :T]\n",
    "    test_game = np.array([test_score, test_opp_score])\n",
    "\n",
    "    if predict_full_game:\n",
    "        to_append = np.ones_like(test_game) * np.mean(train_games)\n",
    "        to_append = to_append.reshape(1, 2, T)\n",
    "    else:\n",
    "        test_half = test_game[:, :half_T]\n",
    "        fill_in = np.ones_like(test_half) * np.mean(train_games)\n",
    "        to_append = np.hstack((test_half, fill_in)).reshape(1, 2, T)\n",
    "    \n",
    "    all_games = np.vstack((train_games, to_append))\n",
    "\n",
    "    # Train Model\n",
    "    team_model = PMF(n_factors=n_factors, reg_lambda=reg_lambda, max_iter=max_iter)\n",
    "    if use_all_data:\n",
    "        train_lists = interleave_lists(all_games[0, :-1], all_games[1, :-1])\n",
    "        train_set = np.vstack([train_lists, all_games[0, -1:]])\n",
    "        mask = np.zeros_like(train_set)\n",
    "        mask[-1, half_T:] = 1\n",
    "        team_model.fit(train_set, mask=mask, r=r)\n",
    "    else:\n",
    "        mask = np.ones_like(all_games[0, :])\n",
    "        if predict_full_game:\n",
    "            mask[-1, :] = 0\n",
    "        else:\n",
    "            mask[-1, half_T:] = 0\n",
    "            \n",
    "        team_model.fit(all_games[0, :], mask=mask, r=r)\n",
    "\n",
    "    # Use model to reconstruct a the new second half\n",
    "    if predict_full_game:\n",
    "        pred_second_halves = team_model.generate_game_prediction(1000)\n",
    "        pred_second_half = np.mean(pred_second_halves, axis=0)\n",
    "    else:\n",
    "        pred_second_half = team_model.predict_second_half(\n",
    "            None, \n",
    "            train_games=all_games[0, :-1] if not use_all_data else train_set,\n",
    "            predict_full_game=predict_full_game\n",
    "        )\n",
    "\n",
    "    if predict_full_game:\n",
    "        mse = np.mean((pred_second_half - test_game[0, :]) ** 2)\n",
    "    else:\n",
    "        mse = np.mean((pred_second_half - test_game[0, half_T:]) **2)\n",
    "\n",
    "    opp_model = PMF(n_factors=n_factors, reg_lambda=reg_lambda, max_iter=max_iter)\n",
    "    if use_all_data:\n",
    "        train_lists = interleave_lists(all_games[0, :-1], all_games[1, :-1])\n",
    "        train_set = np.vstack([train_lists, all_games[1, -1:]])\n",
    "        opp_model.fit(train_set, mask=mask, r=r)\n",
    "    else:\n",
    "        opp_model.fit(all_games[1, :], mask=mask, r=r)\n",
    "    \n",
    "    if predict_full_game:\n",
    "        opp_pred_second_halves = opp_model.generate_game_prediction(1000)\n",
    "        opp_pred_second_half = np.mean(opp_pred_second_halves, axis=0)\n",
    "    else:\n",
    "        opp_pred_second_half = opp_model.predict_second_half(\n",
    "            None, \n",
    "            train_games=all_games[1, :-1] if not use_all_data else train_set,\n",
    "            predict_full_game=predict_full_game\n",
    "        )\n",
    "\n",
    "    if predict_full_game:\n",
    "        opp_mse = np.mean((opp_pred_second_half - test_game[1, :]) ** 2)\n",
    "    else:\n",
    "        opp_mse = np.mean((opp_pred_second_half - test_game[1, half_T:]) ** 2)\n",
    "\n",
    "    if plot:\n",
    "        print(f\"MSE: {mse:.4f}, Opp MSE: {opp_mse:.4f}\")\n",
    "        \n",
    "        plot_predictions= np.array([predictions])\n",
    "        \n",
    "        # Plot results for a random test game\n",
    "        game_idx = 0\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        if predict_full_game:\n",
    "            plt.plot(range(T), test_game[game_idx], label=\"Actual\")\n",
    "            plt.plot(range(T), pred_second_half, 'r--', label=\"Predicted\")\n",
    "        else:\n",
    "            # Plot first half (actual)\n",
    "            first_half = test_game[game_idx, :n_timepoints_per_half]\n",
    "            plt.plot(range(n_timepoints_per_half), first_half, 'b-', label='First Half (Actual)')\n",
    "            \n",
    "            # Plot second half (actual)\n",
    "            second_half = test_game[game_idx, n_timepoints_per_half:]\n",
    "            plt.plot(range(n_timepoints_per_half, n_timepoints_per_half*2), \n",
    "                     second_half, 'g-', label='Second Half (Actual)')\n",
    "            \n",
    "            plt.plot(range(n_timepoints_per_half, n_timepoints_per_half*2), \n",
    "                     pred_second_half, 'r--', label='Second Half (Predicted)')\n",
    "        \n",
    "        plt.axvline(x=n_timepoints_per_half, color='k', linestyle='--')\n",
    "        plt.xlabel('Time point (24-second intervals)')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Game Score Prediction')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if predict_full_game:\n",
    "        full_pred_team = np.cumsum(pred_second_half)\n",
    "        full_pred_opp = np.cumsum(opp_pred_second_half)\n",
    "    else:\n",
    "        full_pred_team = np.cumsum(np.hstack([test_game[0, :n_timepoints_per_half], pred_second_half]))\n",
    "        full_pred_opp = np.cumsum(np.hstack([test_game[1, :n_timepoints_per_half], opp_pred_second_half]))\n",
    "\n",
    "    if predict_full_game:\n",
    "        return [full_pred_team, full_pred_opp], [np.cumsum(test_score), np.cumsum(test_opp_score)], 0.0, [pred_second_halves, opp_pred_second_halves]\n",
    "    return [full_pred_team, full_pred_opp], [np.cumsum(test_score), np.cumsum(test_opp_score)], 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e58bc-1418-4794-8167-f36311585017",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, actual = [], 0\n",
    "preds, reals, _, all_pred_games = predict_last_game_pmf_reconstruct('Arkansas', plot=False, n_factors=30, seed=i, predict_full_game=True)\n",
    "\n",
    "predictions = []\n",
    "print(f\"{np.array(all_pred_games).shape=}\")\n",
    "for game in tqdm(all_pred_games[0]):\n",
    "    tot = np.cumsum(game)\n",
    "    plt.plot(tot)\n",
    "    if tot[-1] > 150:\n",
    "        continue\n",
    "    predictions.append(tot[-1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.hist(predictions)\n",
    "plt.show()\n",
    "\n",
    "actual = reals[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e06f59-a069-43da-9f74-b84e511a1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions), np.std(predictions), actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761baf9-5c66-412c-8778-dd4e02b0b307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions, actual = [], 0\n",
    "preds, reals, _, all_pred_games = predict_last_game_pmf_embed(\n",
    "    team_name='Arkansas', n_factors=30, plot=True, \n",
    "    seed=2, r=100, reg_lambda=0.5, use_all_data=False,\n",
    "    top_k=200, predict_full_game=True\n",
    ")\n",
    "\n",
    "predictions = []\n",
    "print(f\"{np.array(all_pred_games).shape=}\")\n",
    "for game in tqdm(all_pred_games[0]):\n",
    "    tot = np.cumsum(game)\n",
    "    plt.plot(tot)\n",
    "    if tot[-1] > 150:\n",
    "        continue\n",
    "    predictions.append(tot[-1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.hist(predictions)\n",
    "plt.show()\n",
    "\n",
    "actual = reals[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204fc89-dbdd-4821-b88c-17fcc913cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions), np.std(predictions), actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ebb54-7ff5-4d76-ab6f-8ebc2297200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors_pmf_embed(team_name, T=100, interval_seconds=24, n_factors=2):\n",
    "    predictions, opp_predictions, actual, opp_actual = [], [], 0, 0\n",
    "    for i in range(10):\n",
    "        preds, reals, _ = predict_last_game_pmf_embed(\n",
    "            team_name=team_name, n_factors=n_factors, plot=False, top_k=200,\n",
    "            seed=i, r=100, reg_lambda=0.5\n",
    "        )\n",
    "        predictions.append(preds[0][-1])\n",
    "        opp_predictions.append(preds[1][-1])\n",
    "        actual = reals[0][-1]\n",
    "        opp_actual = reals[1][-1]\n",
    "\n",
    "    team_pred, opp_pred = np.mean(predictions), np.mean(opp_predictions)\n",
    "    team_score_err = np.abs(team_pred - actual)\n",
    "    opp_score_err = np.abs(opp_pred - opp_actual)\n",
    "    total_err = np.abs((team_pred + opp_pred) - (actual + opp_actual))\n",
    "    return team_score_err, opp_score_err, total_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87598ee0-6fdc-4513-926f-827393d36b11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs, problem_teams = [], [], [], set()\n",
    "for team_name in TOURNAMENT_TEAMS:\n",
    "    try:\n",
    "        new_team_err, new_opp_err, new_total_err = get_errors_pmf_embed(team_name, n_factors=30)\n",
    "        if new_team_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            team_errs.append(new_team_err)\n",
    "    \n",
    "        if new_opp_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            opp_errs.append(new_opp_err)\n",
    "    \n",
    "        if new_total_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            total_errs.append(new_total_err)\n",
    "            \n",
    "    except ValueError:\n",
    "        print(f\"Failed on team: {team_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f0244-6795-42e6-b051-babd8be4c71e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(team_errs), np.std(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29253ec3-5470-4a98-9dfc-8686f47ce43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(opp_errs), np.std(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d6e96-dee4-4a54-839a-2ba8f9a86ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_errs), np.std(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db16f2-bf61-4880-9d20-b6c52d93c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d914d-326d-4f59-998d-eeac7a57eeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9464a087-ab7b-4ab1-87c1-61cb06518449",
   "metadata": {},
   "source": [
    "## Full Game PMF Embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e9422-b200-4bdd-99f8-000d49426994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_full_game_pmf_embed(\n",
    "    team_name, \n",
    "    embedded_matchups,\n",
    "    heuristic_indices=[4, 3],\n",
    "    top_k=200,\n",
    "    T=100,\n",
    "    interval_seconds=24, \n",
    "    n_factors=30, \n",
    "    max_iter=500, \n",
    "    plot=False, \n",
    "    seed=10,\n",
    "    num_validation_games=3,\n",
    "    r_values = [5, 7.5, 10, 12.5, 15],\n",
    "    reg_lambda_values = [0.5, 0.6, 0.7, 0.8], \n",
    "):   \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Retrieve similar games based on embed\n",
    "    team_scores, opponent_scores, test_score, test_opp_score = get_similar_game_scores(\n",
    "        data_dir, team_name, embedded_matchups, heuristic_indices, interval_seconds=interval_seconds, top_k=top_k\n",
    "    )\n",
    "    \n",
    "    team_scores = np.diff(team_scores)\n",
    "    opponent_scores = np.diff(opponent_scores)\n",
    "    test_score = np.diff(test_score)\n",
    "    test_opp_score = np.diff(test_opp_score)\n",
    "    N = len(team_scores)\n",
    "\n",
    "    train_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(5, N-num_validation_games)])[:, :, :T]\n",
    "    val_games = np.array([[team_scores[i], opponent_scores[i]] for i in range(N - num_validation_games, N)])[:, :, :T]\n",
    "    test_game = np.array([test_score, test_opp_score])[:, :T]\n",
    "    N = len(train_games)\n",
    "\n",
    "    # Fill matrix with fake game that just have average (For reconstruction tasks)\n",
    "    to_append = np.ones_like(test_game) * np.mean(train_games)\n",
    "    to_append = to_append.reshape(1, 2, T)\n",
    "    all_games = np.vstack((train_games, to_append))\n",
    "\n",
    "    # Hyperparameter Search with Validation Games\n",
    "    mask = np.ones_like(all_games[0, :])\n",
    "    mask[-1, :] = 0\n",
    "    \n",
    "    team_r, team_reg_lambda = hyperparameter_search(\n",
    "        all_games[0, :], val_games[0, :], r_values, \n",
    "        reg_lambda_values, max_iter, n_factors, mask\n",
    "    )\n",
    "                \n",
    "    # Train Model with best parameters on Validation Games\n",
    "    team_model = PMF(n_factors=n_factors, reg_lambda=team_reg_lambda, max_iter=max_iter)\n",
    "    team_model.fit(all_games[0, :], mask=mask, r=team_r)\n",
    "\n",
    "    # Use model to reconstruct a the new second half\n",
    "    pred_second_halves = team_model.generate_game_prediction(1000)\n",
    "    pred_second_half = np.mean(pred_second_halves, axis=0)\n",
    "\n",
    "    mse = np.mean((pred_second_half - test_game[0, :]) ** 2)\n",
    "\n",
    "    # Hyperparameter Search for Opponent Model\n",
    "    opp_r, opp_reg_lambda = hyperparameter_search(\n",
    "        all_games[1, :], val_games[1, :], r_values,\n",
    "        reg_lambda_values, max_iter, n_factors, mask\n",
    "    )\n",
    "\n",
    "    # Train Opponent Model with Validation Games\n",
    "    opp_model = PMF(n_factors=n_factors, reg_lambda=opp_reg_lambda, max_iter=max_iter)\n",
    "    opp_model.fit(all_games[1, :], mask=mask, r=opp_r)\n",
    "    opp_pred_second_halves = opp_model.generate_game_prediction(1000)\n",
    "    opp_pred_second_half = np.mean(opp_pred_second_halves, axis=0)\n",
    "\n",
    "    opp_mse = np.mean((opp_pred_second_half - test_game[1, :]) ** 2)\n",
    "\n",
    "    if plot:\n",
    "        print(f\"MSE: {mse:.4f}, Opp MSE: {opp_mse:.4f}\")\n",
    "        \n",
    "        plot_predictions= np.array([predictions])\n",
    "        \n",
    "        # Plot results for a random test game\n",
    "        game_idx = 0\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.plot(range(T), test_game[game_idx], label=\"Actual\")\n",
    "        plt.plot(range(T), pred_second_half, 'r--', label=\"Predicted\")\n",
    "        \n",
    "        plt.axvline(x=T//2, color='k', linestyle='--')\n",
    "        plt.xlabel('Time point (24-second intervals)')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Game Score Prediction')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    full_pred_team = np.cumsum(pred_second_half)\n",
    "    full_pred_opp = np.cumsum(opp_pred_second_half)\n",
    "    return ([full_pred_team, full_pred_opp], \n",
    "            [np.cumsum(test_score), np.cumsum(test_opp_score)], \n",
    "            0.0, \n",
    "            [pred_second_halves, opp_pred_second_halves])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7fad12-b021-4690-89f1-cc2a49111ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors_full_game_pmf_embed(team_name, embedded_matchups, T=100, interval_seconds=24, n_factors=2, heuristic_indices=[4, 3], seed=2):\n",
    "    predictions, opp_predictions, actual, opp_actual = [], [], 0, 0\n",
    "    preds, reals, _, all_pred_games = predict_full_game_pmf_embed(\n",
    "        team_name=team_name, \n",
    "        embedded_matchups=embedded_matchups,\n",
    "        heuristic_indices=heuristic_indices,\n",
    "        n_factors=30, plot=False, \n",
    "        seed=seed, top_k=200,\n",
    "        num_validation_games=10\n",
    "    )\n",
    "    \n",
    "    for game in all_pred_games[0]:\n",
    "        tot = np.cumsum(game)\n",
    "        \n",
    "        if tot[-1] > 150:\n",
    "            continue\n",
    "        predictions.append(tot[-1])\n",
    "\n",
    "    for game in all_pred_games[1]:\n",
    "        tot = np.cumsum(game)\n",
    "\n",
    "        if tot[-1] > 150:\n",
    "            continue    \n",
    "        opp_predictions.append(tot[-1])\n",
    "\n",
    "    actual = reals[0][-1]\n",
    "    opp_actual = reals[1][-1]\n",
    "\n",
    "    team_pred, opp_pred = np.median(predictions), np.median(opp_predictions)\n",
    "    team_score_err = np.abs(team_pred - actual)\n",
    "    opp_score_err = np.abs(opp_pred - opp_actual)\n",
    "    total_err = np.abs((team_pred + opp_pred) - (actual + opp_actual))\n",
    "    return team_score_err, opp_score_err, total_err, actual, opp_actual, team_pred, opp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c5b68-aa3b-4c34-a70b-f2ac1d199ebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs, problem_teams = [], [], [], set()\n",
    "team_to_errs = {}\n",
    "team_to_preds = {}\n",
    "for team_name in tqdm(TOURNAMENT_TEAMS):\n",
    "    try:\n",
    "        new_team_err, new_opp_err, new_total_err, team_pred, opp_pred = get_errors_full_game_pmf_embed(team_name, n_factors=30)\n",
    "        if new_team_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            team_errs.append(new_team_err)\n",
    "    \n",
    "        if new_opp_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            opp_errs.append(new_opp_err)\n",
    "    \n",
    "        if new_total_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            total_errs.append(new_total_err)\n",
    "\n",
    "        team_to_errs[team_name] = (new_team_err, new_opp_err, new_total_err)\n",
    "        team_to_preds[team_name] = (team_pred, opp_pred)\n",
    "    except ValueError:\n",
    "        print(f\"Failed on team: {team_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c4fbf5-5071-428f-8e40-d8a231781490",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(team_errs), np.nanstd(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9dc93e-63c0-45a7-9e84-4496f788d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(opp_errs), np.nanstd(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6fa94-0e08-4cd9-a2fe-291b82d7b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(total_errs), np.nanstd(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c4f8a-8aae-4a6a-a931-a18a536a7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e792ef-3a53-4e3d-bd3e-6d0980c579e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_to_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f2fa4-1e9a-4f48-bdf9-20f2529ef578",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_to_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5445a-9cad-44ef-9630-e0d8bfad482f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f54b7a48-0e68-448c-af37-f6f7033dda33",
   "metadata": {},
   "source": [
    "## More Stats For Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa3762-49ac-4ca7-b41c-45044410073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(combined_df.columns):\n",
    "    print(f\"{i}: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb78442-2efd-4dac-ac10-4d4f66e82d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_indices = [20, 19]\n",
    "all_matchups = get_all_matchups()\n",
    "embedded_matchups = make_matchup_embeds(all_matchups, heuristic_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0f621-fa30-42b4-8bd4-4b295f0b6bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_errs, opp_errs, total_errs, problem_teams = [], [], [], set()\n",
    "team_to_errs = {}\n",
    "team_to_preds = {}\n",
    "for team_name in tqdm(TOURNAMENT_TEAMS):\n",
    "    try:\n",
    "        new_team_err, new_opp_err, new_total_err, actual, opp_actual, team_pred, opp_pred = get_errors_full_game_pmf_embed(\n",
    "            team_name, embedded_matchups, n_factors=30, heuristic_indices=heuristic_indices\n",
    "        )\n",
    "        if new_team_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            team_errs.append(new_team_err)\n",
    "    \n",
    "        if new_opp_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            opp_errs.append(new_opp_err)\n",
    "    \n",
    "        if new_total_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            total_errs.append(new_total_err)\n",
    "\n",
    "        team_to_errs[team_name] = (new_team_err, new_opp_err, new_total_err)\n",
    "        team_to_preds[team_name] = (actual, opp_actual, team_pred, opp_pred)\n",
    "    except ValueError:\n",
    "        print(f\"Failed on team: {team_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29795a-9b85-4b9a-9b34-043215374cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(team_errs), np.nanstd(team_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d356d-fe9e-4a52-93a4-1b12b85a7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(opp_errs), np.nanstd(opp_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0864a0-2b25-48ed-9179-22361989bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(total_errs), np.nanstd(total_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d544053-ed95-43ae-994d-7ce644917a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef15a49-73c2-44bf-9891-52e860df5845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_to_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f302c-acfb-4495-8105-34d0920c5ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_to_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f464a-b1ae-4442-bb15-5cead006b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_over_under_return(game_odds, team_to_preds, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22d513-5573-411b-b489-1b09bd889c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_spread_return(game_odds, team_to_preds, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7e3f0-acb6-4929-86e7-09983612f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_over_under_return(game_odds, team_to_preds, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9ba7d-eb3a-44ac-83b5-90ba24c4869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_spread_return(game_odds, team_to_preds, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad43bac-f02f-4718-b2ff-d707bf2434f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_err(heuristic_indices):\n",
    "    all_matchups = get_all_matchups()\n",
    "    embedded_matchups = make_matchup_embeds(all_matchups, heuristic_indices)    \n",
    "\n",
    "    team_errs, opp_errs, total_errs, problem_teams = [], [], [], set()\n",
    "    team_to_errs = {}\n",
    "    team_to_preds = {}\n",
    "    for team_name in tqdm(TOURNAMENT_TEAMS[:6]):\n",
    "        new_team_err, new_opp_err, new_total_err, actual, opp_actual, team_pred, opp_pred = get_errors_full_game_pmf_embed(\n",
    "            team_name, embedded_matchups, n_factors=30, heuristic_indices=heuristic_indices\n",
    "        )\n",
    "        if new_team_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            team_errs.append(new_team_err)\n",
    "    \n",
    "        if new_opp_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            opp_errs.append(new_opp_err)\n",
    "    \n",
    "        if new_total_err > 100:\n",
    "            problem_teams.add(team_name)\n",
    "        else:\n",
    "            total_errs.append(new_total_err)\n",
    "\n",
    "        team_to_errs[team_name] = (new_team_err, new_opp_err, new_total_err)\n",
    "        team_to_preds[team_name] = (actual, opp_actual, team_pred, opp_pred)\n",
    "\n",
    "    return np.nanmean(total_errs) + np.nanmean(team_errs)\n",
    "\n",
    "def custom_rfe(n_features=10):\n",
    "    \"\"\"\n",
    "    Recursive Feature Elimination\n",
    "    \"\"\"\n",
    "    remaining_indices = list(range(1, len(combined_df.columns) - 9))\n",
    "    eliminated_indices = []\n",
    "    \n",
    "    while len(remaining_indices) > n_features:\n",
    "        worst_index = None\n",
    "        best_mae = float('inf')\n",
    "        \n",
    "        # Try removing each feature one at a time\n",
    "        for i, index in enumerate(remaining_indices):\n",
    "            # Create a set without this feature\n",
    "            test_indices = remaining_indices.copy()\n",
    "            test_indices.pop(i)\n",
    "\n",
    "            print(test_indices)\n",
    "            \n",
    "            mae = get_final_err(test_indices)\n",
    "            \n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                worst_index = index\n",
    "        \n",
    "        # Remove the feature that, when removed, gives the best performance\n",
    "        if worst_index is not None:\n",
    "            remaining_indices.remove(worst_index)\n",
    "            eliminated_indices.append(worst_index)\n",
    "            print(f\"Eliminated feature {worst_index} ({combined_df.columns[worst_index-1]}), MAE: {best_mae}\")\n",
    "    \n",
    "    return remaining_indices, best_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984de325-aea7-4d8d-ab6f-fc2997f1adb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remaining_indices, final_mae = custom_rfe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4301c882-b889-46c8-9616-ae7fcdcf440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_indices, final_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85905c-a3f2-497d-8b52-8e5e5309a797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
